{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as req\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Adjust Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairfax = pd.read_csv(\"data/df_fairfax_cleaned.csv\" ,index_col=[0])\n",
    "df_connecticut = pd.read_csv(\"data/df_connecticut_cleaned.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairfax_addr = df_fairfax[[\"city\", \"addr\", \"county\"]].drop_duplicates()\n",
    "df_connecticut_addr = df_connecticut[[\"city\", \"addr\", \"county\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairfax_addr[\"state\"] = \"Virginia\"\n",
    "df_connecticut_addr[\"state\"] = \"Connecticut\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_fairfax_addr, df_connecticut_addr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"addr\"] = df_combined.addr.str.title()\n",
    "df_combined[\"city\"] = df_combined.city.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = df_combined.addr.str.replace(\" \", \"%20\") + \"%20\" + df_combined.city + \"%20\" + df_combined.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_string = f\"https://nominatim.openstreetmap.org/search?q={locations.iloc[2]}&format=json&addressdetails=1&limit=1&polygon_svg=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(request_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responds = req.get(request_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_list = []\n",
    "long_list = []\n",
    "i = 0\n",
    "for loc in locations:\n",
    "    request_string = f\"https://nominatim.openstreetmap.org/search?q={loc}&format=json&addressdetails=1&limit=1&polygon_svg=1\"\n",
    "    responds = req.get(request_string)\n",
    "\n",
    "    if (responds.status_code == 200) & len(responds.json()) != 0:\n",
    "        lat_list.append(responds.json()[0][\"lat\"])\n",
    "        long_list.append(responds.json()[0][\"lon\"])\n",
    "    else:\n",
    "        lat_list.append(np.nan)\n",
    "        long_list.append(np.nan)\n",
    "    i += 1\n",
    "    print(i)\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geocoded_addr = df_combined.iloc[0:4278]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geocoded_addr.loc[:,\"latitude\"] = lat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geocoded_addr.loc[:,\"longitude\"] = long_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geocoded_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geocoded_addr.to_csv(\"df_geocoded_addr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adress Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save geojson as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = [\n",
    "            \"new_haven\",\n",
    "            \"new_london\",\n",
    "            \"middlesex\",\n",
    "            \"litchfield\",\n",
    "            \"hartford\",\n",
    "            \"fairfield\",\n",
    "            \"tolland\",\n",
    "            \"windham\",\n",
    "            \"fairfax1\",\n",
    "            ]\n",
    "\n",
    "for c in counties:\n",
    "    df = gpd.read_file(f\"/Volumes/Seagate/bavillion/geocoding3/{c}.geojson\")\n",
    "    df = df[['addr:city',\n",
    "        'addr:country',\n",
    "        'addr:housename',\n",
    "        'addr:housenumber',\n",
    "        'addr:postcode',\n",
    "        'addr:state',\n",
    "        'addr:street', \"geometry\"]]\n",
    "    df = df.dropna(subset=[\"addr:street\"])\n",
    "    df = df.rename(columns={\"addr:housenumber\": \"housenr\", \"addr:city\": \"city\", \"addr:street\":\"addr\"})\n",
    "    df[[\"city\", \"addr\", \"housenr\", 'addr:postcode', \"geometry\"]].to_csv(f\"df_geo_{c}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.dropna(subset=[\"addr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rt change to CT (Route) e.g. Rt-171 to Rt (CT-171)\n",
    "- Dr change to Drive e.g. Hemlock Dr to Hemlock Drive\n",
    "- Change st to Street\n",
    "- Ext to Extension\n",
    "- La to Lane\n",
    "- Tpke to Turnpike\n",
    "- Cir to Circle\n",
    "\n",
    "\n",
    "- So -> South\n",
    "- No -> North\n",
    "\n",
    "- Resv -> Reservoir\n",
    "- \" Rd \" -> \" Road \"\n",
    "- \" St \" -> \" Street \"\n",
    "- \"Ln\" -> \"Lane\"\n",
    "\n",
    "- Nur wenn erster Teil eine Zahl enthÃ¤lt splitten e.g. 23A Street -> 23 Street; Street Drive -> Street Drive\n",
    "- Zahlen am Ende von street entfernen\n",
    "- Einzelne Buchstaben vor oder nach Street entfernen\n",
    "\n",
    "- Boston Pike (nicht gefunden)\n",
    "\n",
    "\n",
    "- Mt -> Mount\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning Adress Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_digits(street):\n",
    "    first_split = street.split(' ')[0]\n",
    "    if re.search('\\d+', first_split):\n",
    "        return ' '.join(street.split(' ')[1:])\n",
    "    else:\n",
    "        return street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(housenumber):\n",
    "    match = re.match(r'^\\d+', housenumber)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else: \n",
    "        return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_end_digits(street):\n",
    "    if \"Route\" in street:\n",
    "        return street\n",
    "    else:\n",
    "        return re.sub(r'(?:\\d+[+-]\\d*|[-+]\\d+|\\d+[A-Za-z]*)(\\s|$)', '', street)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_start_digits(street):\n",
    "    if \"Route\" in street:\n",
    "        return street\n",
    "    else:\n",
    "        return re.sub(r'(\\s|^)(?:\\d+[+-]\\d*|[-+]\\d+|\\d+[A-Za-z]*)', '', street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_the_to_front(street):\n",
    "    if re.search(r\"\\bThe\\b\", street):\n",
    "        street = re.sub(r\"\\bThe\\b\", \"\", street)\n",
    "        street = street.replace(\"()\", \"\").strip()\n",
    "        street = street.strip(\",\")\n",
    "        return \"The \" + street.strip()  \n",
    "    else:\n",
    "        return street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_the_to_front(\"Knoll, The\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_split(street):\n",
    "    parts = re.split(r\"/|&|\\\\\", street)\n",
    "    if len(parts) > 1:\n",
    "        first = (parts[0]\n",
    "                .strip()\n",
    "                .strip(\"-\")\n",
    "                .strip(\".\")\n",
    "                )\n",
    "        \n",
    "        if first.isdigit() or (first == \"\"):\n",
    "            return parts[1]\n",
    "        return parts[0]\n",
    "    return street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_letters(street):\n",
    "    if re.search(r\"\\bB Lane\", street):\n",
    "        return re.sub(r\"\\b(?!')[a-zA-Z]$\", \"\", street.strip())\n",
    "    elif re.search(r\"Avenue B(\\s|$)\", street) or re.search(r\"Aaron B(\\s|$)\", street) or re.search(r\"Ave B(\\s|$)\", street):\n",
    "        return re.sub(r\"^[a-zA-Z]\\b(?!')\", \" \", street.strip())\n",
    "    else:\n",
    "        return re.sub(r\"(^)\\b(?!')[a-zA-Z]\\b(?!')|\\b(?!')[a-zA-Z]\\b(?!')($)\", '', street)\n",
    "        #return re.sub(r\"(^|\\s)\\b(?<!')[a-zA-Z]\\b(?<!')|\\b(?<!')[a-zA-Z]\\b(?<!')($|\\s)\", '', street)\n",
    "        #return re.sub(r'(^|\\s)[a-zA-Z]\\s|\\s[a-zA-Z]($|\\s)', '', street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_paran(street):\n",
    "    return re.sub(r'\\(.*?$', \"\", street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbrv(df_addr):\n",
    "    return (df_addr.apply(lambda x: re.sub(r\"St Joseph\", \"Saint Joseph\", x))\n",
    "                      .apply(lambda x: re.sub(r\"St($|\\b)\", \"Street \", x))\n",
    "                      .apply(lambda x: re.sub(r'\\bUnit(\\b|$)\\.*', '', x))\n",
    "                      .apply(lambda x: re.sub(r\"Ct($|\\b)\", \"Court \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Crt($|\\b)\", \"Court \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cor($|\\b)\", \"Corner \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ctr($|\\b)\", \"Center \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Av($|\\s|\\b)\", \"Avenue \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ave($|\\s|\\b)\", \"Avenue \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Apts($|\\b)\", \"Apartments \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Al($|\\b)\", \"Alley \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tr($|\\b)\", \"Terrace \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Terr($|\\b)\", \"Terrace \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Te($|\\b)\", \"Terrace \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Trce($|\\b)\", \"Trace\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Thse($|\\b)\", \"Townhouse \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pl($|\\b)\", \"Place \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Wy($|\\b)\", \"Way \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Wa($|\\b)\", \"Way \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ter($|\\b)\", \"Terrace \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Blvd($|\\b)\", \"Boulevard \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bl($|\\b)\", \"Boulevard \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bv($|\\b)\", \"Boulevard \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Blv($|\\b)\", \"Boulevard \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bch($|\\b)\", \"Beach \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cmn($|\\b)\", \"Common \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cmns($|\\b)\", \"Commons \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hol($|\\b)\", \"Hollow \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hlw($|\\b)\", \"Hollow \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Sq($|\\b)\", \"Square \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Trl($|\\b)\", \"Trail \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tl($|\\b)\", \"Trail \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hwy($|\\b)\", \"Highway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hi($|\\b)\", \"Highway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hgwy($|\\b)\", \"Highway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lndg($|\\b)\", \"Landing \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pt($|\\b)\", \"Point \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Po($|\\b)\", \"Point \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pro($|\\b)\", \"Professional \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Brk($|\\b)\", \"Brook \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rdg($|\\b)\", \"Ridge \", x))\n",
    "                      .apply(lambda x: re.sub(r\"So($|\\b)\", \"South \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tp($|\\b)\", \"Turnpike \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tpk($|\\b)\", \"Turnpike \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tpke($|\\b)\", \"Turnpike \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tnpk($|\\b)\", \"Turnpike \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bp($|\\b)\", \"Bridgeport \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Br($|\\b)\", \"Bridge \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pkwy($|\\b)\", \"Parkway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pky($|\\b)\", \"Parkway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Vw($|\\b)\", \"View \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cv($|\\b)\", \"Cove \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ave($|\\b)\", \"Avenue \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Dr($|\\b)\", \"Drive \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cr($|\\b)\", \"Circle \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ci($|\\b)\", \"Circle \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cir($|\\b)\", \"Circle \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cl($|\\b)\", \"Close \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cswy($|\\b)\", \"Causeway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cres($|\\b)\", \"Crescent \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Se($|\\b)\", \"Southeast \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Sw($|\\b)\", \"Southwest \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Nw($|\\b)\", \"Northwest \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ne($|\\b)\", \"Northeast \", x))\n",
    "                      .apply(lambda x: re.sub(r\"No($|\\b)\", \"North \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Plz($|\\b)\", \"Plaza \", x))\n",
    "                      #.apply(lambda x: re.sub(r\"Ptwy($|\\s)\", \"Pentway \", x)) ????\n",
    "                      .apply(lambda x: re.sub(r\"Ptwy($|\\b)\", \"Pathway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pth($|\\b)\", \"Path \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Grv($|\\b)\", \"Grove \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Gr($|\\b)\", \"Grove \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Drs($|\\b)\", \"Drive \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hgts($|\\b)\", \"Heights \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hghts($|\\b)\", \"Heights \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hts($|\\b)\", \"Heights \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ht($|\\b)\", \"Heights \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hl($|\\b)\", \"Hill \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hls($|\\b)\", \"Hills \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pk($|\\b)\", \"Park \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rdg($|\\b)\", \"Ridge \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ex($|\\b)\", \"Extension \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ext($|\\b)\", \"Extension \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rte($|\\b)\", \"Route \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rd($|\\b)\", \"Road \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rvr($|\\b)\", \"River \", x))\n",
    "                      .apply(lambda x: re.sub(r\"La($|\\b)\", \"Lane \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ln($|\\b)\", \"Lane \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ldg($|\\b)\", \"Lodge \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mtn($|\\b)\", \"Mountain \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mt($|\\b)\", \"Mountain \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ind($|\\b)\", \"Industrial \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lk($|\\b)\", \"Lake \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Vlg($|\\b)\", \"Village \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mnr($|\\b)\", \"Manor \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Knls($|\\b)\", \"Knolls \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Knl($|\\b)\", \"Knoll \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pswy($|\\b)\", \"Passway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Qtr($|\\b)\", \"Quarter \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mdw($|\\b)\", \"Meadow \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Vly($|\\b)\", \"Valley \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Kn($|\\b)\", \"Knoll \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Grn($|\\b)\", \"Green \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Is($|\\b)\", \"Island \", x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = df.dropna(subset=\"addr\")\n",
    "    df[\"housenr\"] = df[\"addr\"].apply(lambda x:np.nan if x==np.nan else re.split(r\"\\s|/\", x)[0])\n",
    "    df[\"housenr\"] = df[\"housenr\"].apply(match)\n",
    "    df[\"addr_mod\"] = (df[\"addr\"].apply(split_digits)\n",
    "                      .str.strip(\"-\")\n",
    "                      .apply(lambda x: x if not x.strip().endswith('La') else x.replace('La', 'Lane'))\n",
    "                      .apply(lambda x: x if not x.strip().endswith('Ext') else x.replace('Ext', 'Extension'))\n",
    "                      .apply(lambda x: re.sub(r\"\\-[A-Z]$\", \"\",x))\n",
    "                      .apply(lambda x: re.sub(r\"\\s[A-Z]\\-[A-Z]\\s\", \"\",x))\n",
    "                      .str.replace(\"Rt \", \"Route \")\n",
    "                      .str.replace('No ', 'North ')\n",
    "                      .str.replace(' No ', ' North ')\n",
    "                      .str.replace('Resv ', 'Reservoir ')\n",
    "                      .str.replace(' Resv ', ' Reservoir ')\n",
    "                      .str.replace(' Rd ', ' Road ')\n",
    "                      .str.replace(' La ', ' Lane ')\n",
    "                      .str.replace('Talcott Forest Road East', 'Talcott Forest Road') #???\n",
    "                      .apply(lambda x: re.sub(r'\\bLn(\\s|$)', \"Lane \", x))\n",
    "                      .str.replace(' Tpke ', ' Turnpike ')\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)N($|\\s)\", \" North \", x))\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)W($|\\s)\", \" West \", x))\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)S($|\\s)\", \" South  \", x))\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)E($|\\s)\", \" East \", x))\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)N W($|\\s)\", \" Northwest \", x))\n",
    "                      .apply(put_the_to_front)\n",
    "                      .apply(lambda x: re.sub(\"O Neill\", \"O'Neill\", x))\n",
    "                      .apply(lambda x: re.sub(r\"O Brien\", \"O'Brien\", x))\n",
    "                      .apply(lambda x: re.sub(r\"O Clock\", \"O'Clock\", x))\n",
    "                      .apply(lambda x: re.sub(r\"O Rocks\", \"O'Rocks\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Wells Place Place\", \"Wells Place\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Alexander D \", \"Alexander Drive \", x))\n",
    "                      #.apply(lambda x: re.sub(r\"(^|\\s)\\b[a-zA-Z](?!['])\\b|\\b[a-zA-Z](?!['])\\b($|\\s)\", '', x))\n",
    "                      #.apply(lambda x: re.sub(r\"^\\b[a-zA-Z]\\b(?!')|\\b[a-zA-Z]\\b(?!')$\", '', x))\n",
    "                      .apply(remove_letters)\n",
    "                      .apply(lambda x: re.sub(r'\\(.*?\\)', \"\", x)) # remove (\"any string\")\n",
    "                      .apply(remove_end_digits)\n",
    "                      .apply(ad_split)\n",
    "                      .apply(lambda x: re.sub(r\"#\\S*\", \"\", x))\n",
    "                      .str.strip()\n",
    "                      .str.strip(\",\")\n",
    "                      .str.strip(\".\")\n",
    "                      .str.strip()\n",
    "    )\n",
    "    df[\"addr_mod\"] = abbrv(df[\"addr_mod\"])\n",
    "    df[\"addr_mod\"] = (df[\"addr_mod\"]\n",
    "                      #.apply(lambda x: re.split(r\"/|&\", x)[0])\n",
    "                      .str.replace(\"#North\", \"North\")\n",
    "                      .str.replace(\"#South\", \"South\")\n",
    "                      .str.replace(\"#West\", \"West\")\n",
    "                      .str.replace(\"#East\", \"East\")\n",
    "                      .str.replace(\"#Wy\", \"Way\")\n",
    "                      #.apply(lambda x: re.sub(r'(^|\\s)\\b[a-zA-Z]\\b|\\b[a-zA-Z]\\b($|\\s)', '', x))\n",
    "                      .apply(remove_letters)\n",
    "                      .str.replace(\"- Union\", \"Union\")\n",
    "                      .str.replace(\"- Extension\", \"Extension\")\n",
    "                      .str.replace(\"-Extension\", \"Extension\")\n",
    "                      .str.replace(\"Nrwh Wstly\", \"Norwich Westerly\")\n",
    "                      .str.replace(\"Avenue-Extension\", \"Avenue Extension\")\n",
    "                      .str.replace(\"  \", \" \")\n",
    "                      .str.strip(\"_\")\n",
    "                      .str.strip()\n",
    "                      .apply(lambda x: re.sub(r\"^[\\d\\s.]*\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rear$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Re$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rea$\", \"Rear\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Gar$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lt$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Adj$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Aka$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ch$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ch2$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ctg$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ul$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cb$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ogba$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Gnh$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bpbc$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lowr$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lp$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Om$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ply$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Preq$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lz$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rz$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Abcd$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Eb$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Prim$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Osg$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Dwl$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Iii$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ab$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lot$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rr$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bldg$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Beu$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Na$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ph$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Un1$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Una$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Kc$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bh$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mr$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Prvt$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Gnb$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bsmt$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Unit$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Aa$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ru$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Street Land$\", \"Street\", x)) #???\n",
    "                      .apply(remove_end_digits)\n",
    "                      .apply(remove_start_digits)\n",
    "                      #.apply(lambda x: re.sub(r\"\\d+$\", \"\", x))\n",
    "                      #.apply(lambda x: re.sub(r\"\\d+[a-zA-Z]*$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"^\\d+\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Oneill\", \"O'neill\", x))\n",
    "                      .apply(lambda x: re.sub(r\"\\([a-zA-Z\\d]*\\)\", \"\",x)) #??\n",
    "                      .apply(lambda x: re.sub(r\"^Off\\b\", \" \",x)) # ???\n",
    "                      .apply(lambda x: re.sub(r\"^Rdwy\", \"\",x)) # ???\n",
    "                      .apply(lambda x: re.sub(r\"^Lot\\b\", \" \",x)) \n",
    "                      .apply(lambda x: re.sub(r\"^Lot A\", \"\",x)) \n",
    "                      .apply(remove_after_paran)\n",
    "                      .str.replace(\"Fish Game\", \"Fish + Game\")\n",
    "                      .str.replace(\"Street Andrews\", \"St Andrews\")\n",
    "                      .str.replace(\"Street John\", \"St John\")\n",
    "                      .str.replace(\"Street Lawrence\", \"St Lawrence\")\n",
    "                      .str.replace(\"Street Paul\", \"St Paul\")\n",
    "                      .str.replace(\"Street Thomas\", \"St Thomas\")\n",
    "                      .str.replace(\"Street Stephens\", \"St Stephens\")\n",
    "                      .str.replace(\"Street Mathias\", \"St Stephens\")\n",
    "                      .str.replace(\"Street Andrew\", \"St Andrew\")\n",
    "                      .str.replace(\"Street James\", \"St James\")\n",
    "                      .str.strip()\n",
    "                      .str.strip(\",\")\n",
    "                      .str.strip(\"-\")\n",
    "                      .apply(remove_letters)\n",
    "                      .str.strip(\"-\")\n",
    "                      .str.strip(\",\")\n",
    "                      .str.strip(\"-\")\n",
    "                      .str.strip(\".\")\n",
    "                      .str.strip(\"+\")\n",
    "                      .str.strip()\n",
    "                      )\n",
    "    df[\"housenr\"] = np.where(df.housenr.str.isdigit(), df.housenr, np.nan)\n",
    "    return df.reset_index(drop=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_adress_to_location(df, df_geo, county=\"all\"):\n",
    "    if county!=\"all\":\n",
    "        df = df[df.county == county]\n",
    "    print(df.shape)\n",
    "    df_merge = df.merge(df_geo, how=\"left\", left_on=[\"addr_mod\", \"housenr\", \"city\"], right_on=[\"addr\", \"housenr\", \"city\"])\n",
    "    df_missings = df_merge[df_merge.geometry.isnull()]\n",
    "    df_found = df_merge.dropna(subset=[\"geometry\"]) \n",
    "    df_missings = df_merge[df_merge.geometry.isnull()]\n",
    "    df_missing_housnr = df_missings[df_missings[\"housenr\"].isnull()]\n",
    "    df_missings = df_missings.dropna(subset=\"housenr\")\n",
    "    df_missing_merge = df_missings.merge(df_geo, how=\"left\", left_on=[\"addr_mod\", \"city\"], right_on=[\"addr\", \"city\"])\n",
    "\n",
    "    df_missing_merge[\"housenr_x\"] = df_missing_merge[\"housenr_x\"].dropna().apply(lambda x: re.sub(r'[a-zA-z]', '', x)).astype(\"float64\")\n",
    "    df_missing_merge[\"housenr_y\"] = (df_missing_merge[\"housenr_y\"].dropna().apply(lambda x: x.split('-')[0])\n",
    "                                     .apply(lambda x: x.split(\"+\")[0])\n",
    "                                     .apply(lambda x: x.split(\"&\")[0])\n",
    "                                     .apply(lambda x: x.split(\";\")[0])\n",
    "                                     .apply(lambda x: x.split(\" \")[0])\n",
    "                                     .apply(lambda x: x.split(\",\")[0])\n",
    "                                     .apply(lambda x: x.split(\"/\")[0])\n",
    "                                     .str.strip(\"#\")\n",
    "                                     .str.strip(\"Ã\")\n",
    "                                     .str.replace(\")\", \"\")\n",
    "                                     .apply(lambda x: re.sub(r'[a-zA-z]', '', x)))\n",
    "    df_missing_merge[\"housenr_y\"] = np.where(df_missing_merge[\"housenr_y\"] == \"\", np.nan, df_missing_merge[\"housenr_y\"]).astype(\"float64\")\n",
    "    df_missing_merge[\"diff\"] = np.abs(df_missing_merge[\"housenr_x\"] - df_missing_merge[\"housenr_y\"])\n",
    "    df_found_2 = df_missing_merge.loc[df_missing_merge.dropna(subset=\"geometry_y\").groupby(by=[\"addr_x\", \"city\"])[\"diff\"].idxmin().dropna()]\n",
    "    df_missing_merge_h = df_missing_housnr.merge(df_geo, how=\"left\", left_on=[\"addr_mod\", \"city\"], right_on=[\"addr\", \"city\"])\n",
    "    df_missing_merge_h = df_missing_merge_h.dropna(subset=\"geometry_y\")\n",
    "    df_found_3 = df_missing_merge_h.dropna(subset=\"geometry_y\").groupby(by=[\"addr_x\", \"city\"]).sample(1)\n",
    "    selected_columns = [\"addr\", \"city\", \"county\", \"state\", \"geometry\"]\n",
    "\n",
    "    \n",
    "    df_found = df_found.rename(columns={\"geometry_y\": \"geometry\", \"addr_x\":\"addr\"})\n",
    "    df_found_2 = df_found_2.drop(columns=\"addr\").rename(columns={\"geometry_y\": \"geometry\", \"addr_x\":\"addr\"})\n",
    "    df_found_3 = df_found_3.drop(columns=\"addr\").rename(columns={\"geometry_y\": \"geometry\", \"addr_x\":\"addr\"})\n",
    "\n",
    "    df_clean = pd.concat([df_found, df_found_2, df_found_3])\n",
    "    return df_clean[selected_columns].reset_index(drop=True).drop_duplicates(subset=[\"addr\", \"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean\n",
    "df_cleaned = clean(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fairfax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairfax = df_cleaned[df_cleaned.county == \"Fairfax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo_fairfax = pd.read_csv(\"df_geo_fairfax1_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipcodes = pd.read_csv(\"ZIP_Codes.csv\")\n",
    "# zipcodes = zipcodes[[\"ZIPCODE\", \"ZIPCITY\"]]\n",
    "df_fairfax_cities = gpd.read_file(\"fairfax_cities.geojson\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_fairfax = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/fairfax_highway.csv\")\n",
    "df_highway_fairfax = df_highway_fairfax[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_fairfax = df_highway_fairfax.dropna(subset=\"geometry\")\n",
    "df_highway_fairfax[\"geometry\"] = df_highway_fairfax[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_fairfax = gpd.GeoDataFrame(df_highway_fairfax)\n",
    "df_highway_fairfax.crs = \"EPSG:4326\"\n",
    "df_highway_fairfax = df_highway_fairfax.sjoin(df_fairfax_cities[[\"ZIPCODE\", \"ZIPCITY\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_fairfax = df_highway_fairfax.drop(columns=[\"tiger:county\", \"index_right\"]).rename(columns={\"ZIPCODE\":\"addr:postcode\", \n",
    "                                \"ZIPCITY\":\"city\", \n",
    "                                \"name\": \"addr\"})\n",
    "df_highway_fairfax[\"city\"] = df_highway_fairfax[\"city\"].str.title()\n",
    "df_highway_fairfax[\"housenr\"] = np.nan\n",
    "df_highway_fairfax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add city to geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo_fairfax.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split(postcode):\n",
    "    if isinstance(postcode, float) and np.isnan(postcode):\n",
    "        return postcode\n",
    "    return postcode.split(\"-\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_geo_fairfax = df_geo_fairfax.dropna(subset=\"addr:postcode\")\n",
    "#df_geo_fairfax[\"addr:postcode\"] = df_geo_fairfax[\"addr:postcode\"].dropna().apply(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "# df_geo_fairfax[\"addr:postcode\"] = df_geo_fairfax[\"addr:postcode\"].apply(_split)\n",
    "# df_geo_fairfax[\"addr:postcode\"] = df_geo_fairfax[\"addr:postcode\"].astype(\"float64\")\n",
    "# df_geo_fairfax = df_geo_fairfax.merge(zipcodes, how=\"left\", left_on=\"addr:postcode\", right_on=\"ZIPCODE\")\n",
    "# df_geo_fairfax = df_geo_fairfax.drop(columns=\"city\").rename(columns={\"ZIPCITY\": \"city\"})\n",
    "\n",
    "df_geo_fairfax[\"geometry\"] = df_geo_fairfax[\"geometry\"].apply(wkt.loads)\n",
    "df_geo_fairfax = gpd.GeoDataFrame(df_geo_fairfax)\n",
    "df_geo_fairfax.crs = \"EPSG:4326\" \n",
    "\n",
    "df_fairfax_cities.crs = \"EPSG:4326\" \n",
    "\n",
    "df_geo_fairfax = df_geo_fairfax.sjoin(df_fairfax_cities[[\"ZIPCODE\", \"ZIPCITY\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_geo_fairfax = df_geo_fairfax.drop(columns=[\"city\", \"addr:postcode\"]).rename(columns={\"ZIPCODE\": \"postcode\", \"ZIPCITY\":\"city\"})\n",
    "\n",
    "df_geo_fairfax[\"city\"] = df_geo_fairfax[\"city\"].str.title()\n",
    "print(df_geo_fairfax.city.isna().sum())\n",
    "\n",
    "grouped_addr = df_fairfax.groupby(by=[\"addr_mod\", \"city\"]).size().to_frame()\n",
    "grouped_addr.columns = [\"size\"]\n",
    "grouped_addr = grouped_addr.reset_index()\n",
    "addr_count = grouped_addr.addr_mod.value_counts().to_frame().reset_index()\n",
    "unique_addr = addr_count[addr_count[\"count\"] == 1].addr_mod.values\n",
    "unique_addr_city = df_fairfax[df_fairfax.addr_mod.isin(unique_addr)][[\"addr_mod\", \"city\"]].drop_duplicates()\n",
    "df_geo_fairfax = df_geo_fairfax.merge(unique_addr_city, how=\"left\", left_on=\"addr\", right_on=\"addr_mod\", suffixes=[\"_geo\", \"_add\"])\n",
    "df_geo_fairfax[\"city\"] = np.where(df_geo_fairfax.city_geo.isna(), df_geo_fairfax.city_add, df_geo_fairfax.city_geo)\n",
    "df_geo_fairfax = df_geo_fairfax.drop(columns=[\"city_geo\", \"city_add\", \"addr_mod\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_fairfax = match_adress_to_location(df_cleaned, df_geo_fairfax, county=\"Fairfax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_fairfax[\"housenr\"] = \"0\"\n",
    "df_geo_fairfax_comb= pd.concat([df_geo_fairfax, df_highway_fairfax])\n",
    "missing_fairfax = df_fairfax[~df_fairfax.addr.isin(match_fairfax.addr)]\n",
    "match_fairfax_2 = match_adress_to_location(missing_fairfax, df_geo_fairfax_comb, county=\"Fairfax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match_fairfax = pd.concat([match_fairfax, match_fairfax_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairfax[~df_fairfax.addr.isin(final_match_fairfax.addr)].addr_mod.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Windham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecticut_zip = gpd.read_file(\"ct_connecticut_zip_codes_geo.min.json\")\n",
    "connecticut_city = pd.read_csv(\"ct_zipcode_city.csv\")\n",
    "connecticut_zip = connecticut_zip[[\"ZCTA5CE10\", \"geometry\"]]\n",
    "connecticut_city = connecticut_city[[\"zip\", \"City\"]]\n",
    "connecticut_city = connecticut_city.dropna(subset=\"City\")\n",
    "connecticut_zip = connecticut_zip.rename(columns={\"ZCTA5CE10\":\"zip\"})\n",
    "connecticut_zip[\"zip\"] = connecticut_zip.zip.str.lstrip(\"0\")\n",
    "connecticut_zip = connecticut_zip.merge(connecticut_city, how=\"left\", on=\"zip\")\n",
    "connecticut_zip[\"City\"] = connecticut_zip.City.str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windham = df_cleaned[df_cleaned.county == \"Windham\"]\n",
    "df_geo_windham = pd.read_csv(\"df_geo_windham_2.csv\", index_col=[0])\n",
    "match_windham = match_adress_to_location(df_cleaned, df_geo_windham, county=\"Windham\")\n",
    "missing_windham = df_windham[~df_windham.addr.isin(match_windham.addr)][[\"addr_mod\", \"addr\", \"state\" ,\"housenr\",\"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")\n",
    "\n",
    "df_highway_windham = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/windham_highway.csv\")\n",
    "df_highway_windham = df_highway_windham[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_windham = df_highway_windham.dropna(subset=\"geometry\")\n",
    "df_highway_windham[\"geometry\"] = df_highway_windham[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_windham = gpd.GeoDataFrame(df_highway_windham)\n",
    "df_highway_windham.crs = \"EPSG:4326\"\n",
    "df_highway_windham = df_highway_windham.sjoin(connecticut_zip[[\"City\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_windham = df_highway_windham.drop(columns=[\"tiger:county\"]).rename(columns={\"name\": \"addr\", \"City\":\"city\"})\n",
    "df_highway_windham[\"city\"] = df_highway_windham[\"city\"].str.title()\n",
    "df_highway_windham[\"housenr\"] = \"0\"\n",
    "\n",
    "df_geo_windham_comb= pd.concat([df_geo_windham, df_highway_windham])\n",
    "missing_winham = df_windham[~df_windham.addr.isin(match_windham.addr)]\n",
    "match_windham_2 = match_adress_to_location(missing_windham, df_geo_windham_comb)\n",
    "final_match_windham = pd.concat([match_windham, match_windham_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tolland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tolland = df_cleaned[df_cleaned.county == \"Tolland\"]\n",
    "df_geo_tolland = pd.read_csv(\"df_geo_tolland_2.csv\", index_col=[0])\n",
    "match_tolland = match_adress_to_location(df_cleaned, df_geo_tolland, county=\"Tolland\")\n",
    "missing_tolland = df_tolland[~df_tolland.addr.isin(match_tolland.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_tolland = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/tolland_highway.csv\")\n",
    "df_highway_tolland = df_highway_tolland[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_tolland = df_highway_tolland.dropna(subset=\"geometry\")\n",
    "df_highway_tolland[\"geometry\"] = df_highway_tolland[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_tolland = gpd.GeoDataFrame(df_highway_tolland)\n",
    "df_highway_tolland.crs = \"EPSG:4326\"\n",
    "df_highway_tolland = df_highway_tolland.sjoin(connecticut_zip[[\"City\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_tolland = df_highway_tolland.drop(columns=[\"tiger:county\"]).rename(columns={\"name\": \"addr\", \"City\":\"city\"})\n",
    "df_highway_tolland[\"city\"] = df_highway_tolland[\"city\"].str.title()\n",
    "df_highway_tolland[\"housenr\"] = \"0\"\n",
    "\n",
    "df_geo_tolland_comb= pd.concat([df_geo_tolland, df_highway_tolland])\n",
    "missing_tolland = df_tolland[~df_tolland.addr.isin(match_tolland.addr)]\n",
    "match_tolland_2 = match_adress_to_location(missing_tolland, df_geo_tolland_comb)\n",
    "final_match_tolland = pd.concat([match_tolland, match_tolland_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_london = df_cleaned[df_cleaned.county == \"New London\"]\n",
    "df_geo_london = pd.read_csv(\"df_geo_new_london_2.csv\", index_col=[0])\n",
    "match_london = match_adress_to_location(df_cleaned, df_geo_london, county=\"New London\")\n",
    "missing_london = df_new_london[~df_new_london.addr.isin(match_london.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_london = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/new_london_highway.csv\")\n",
    "df_highway_london = df_highway_london[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_london = df_highway_london.dropna(subset=\"geometry\")\n",
    "df_highway_london[\"geometry\"] = df_highway_london[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_london = gpd.GeoDataFrame(df_highway_london)\n",
    "df_highway_london.crs = \"EPSG:4326\"\n",
    "df_highway_london = df_highway_london.sjoin(connecticut_zip[[\"City\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_london = df_highway_london.drop(columns=[\"tiger:county\"]).rename(columns={\"name\": \"addr\", \"City\":\"city\"})\n",
    "df_highway_london[\"city\"] = df_highway_london[\"city\"].str.title()\n",
    "df_highway_london[\"housenr\"] = \"0\"\n",
    "\n",
    "df_geo_london_comb= pd.concat([df_geo_london, df_highway_london])\n",
    "missing_london = df_new_london[~df_new_london.addr.isin(match_london.addr)]\n",
    "match_london_2 = match_adress_to_location(missing_london, df_geo_london_comb)\n",
    "final_match_london = pd.concat([match_london, match_london_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New Haven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_haven = df_cleaned[df_cleaned.county == \"New Haven\"]\n",
    "df_geo_haven = pd.read_csv(\"df_geo_new_haven_2.csv\", index_col=[0])\n",
    "match_haven = match_adress_to_location(df_cleaned, df_geo_haven, county=\"New Haven\")\n",
    "missing_haven = df_new_haven[~df_new_haven.addr.isin(match_haven.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_haven = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/new_haven_highway.csv\")\n",
    "df_highway_haven = df_highway_haven[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_haven = df_highway_haven.dropna(subset=\"geometry\")\n",
    "df_highway_haven[\"geometry\"] = df_highway_haven[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_haven = gpd.GeoDataFrame(df_highway_haven)\n",
    "df_highway_haven.crs = \"EPSG:4326\"\n",
    "df_highway_haven = df_highway_haven.sjoin(connecticut_zip[[\"City\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_haven = df_highway_haven.drop(columns=[\"tiger:county\"]).rename(columns={\"name\": \"addr\", \"City\":\"city\"})\n",
    "df_highway_haven[\"city\"] = df_highway_haven[\"city\"].str.title()\n",
    "df_highway_haven[\"housenr\"] = \"0\"\n",
    "\n",
    "df_geo_haven_comb= pd.concat([df_geo_haven, df_highway_haven])\n",
    "missing_haven = df_new_haven[~df_new_haven.addr.isin(match_haven.addr)]\n",
    "match_haven_2 = match_adress_to_location(missing_haven, df_geo_haven_comb)\n",
    "final_match_haven = pd.concat([match_haven, match_haven_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Litchfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_litchfield = df_cleaned[df_cleaned.county == \"Litchfield\"]\n",
    "df_geo_litchfield = pd.read_csv(\"df_geo_litchfield_2.csv\", index_col=[0])\n",
    "match_litchfield = match_adress_to_location(df_cleaned, df_geo_litchfield, county=\"Litchfield\")\n",
    "missing_litchfield = df_litchfield[~df_litchfield.addr.isin(match_litchfield.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_litchfield = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/litchfield_highway.csv\")\n",
    "df_highway_litchfield = df_highway_litchfield[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_litchfield = df_highway_litchfield.dropna(subset=\"geometry\")\n",
    "df_highway_litchfield[\"geometry\"] = df_highway_litchfield[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_litchfield = gpd.GeoDataFrame(df_highway_litchfield)\n",
    "df_highway_litchfield.crs = \"EPSG:4326\"\n",
    "df_highway_litchfield = df_highway_litchfield.sjoin(connecticut_zip[[\"City\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_litchfield = df_highway_litchfield.drop(columns=[\"tiger:county\"]).rename(columns={\"name\": \"addr\", \"City\":\"city\"})\n",
    "df_highway_litchfield[\"city\"] = df_highway_litchfield[\"city\"].str.title()\n",
    "df_highway_litchfield[\"housenr\"] = \"0\"\n",
    "\n",
    "df_geo_litchfield_comb= pd.concat([df_geo_litchfield, df_highway_litchfield])\n",
    "missing_litchfield = df_litchfield[~df_litchfield.addr.isin(match_litchfield.addr)]\n",
    "match_litchfield_2 = match_adress_to_location(missing_litchfield, df_geo_litchfield_comb)\n",
    "final_match_litchfield = pd.concat([match_litchfield, match_litchfield_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hartford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hartford = df_cleaned[df_cleaned.county == \"Hartford\"]\n",
    "df_geo_hartford = pd.read_csv(\"df_geo_hartford_2.csv\", index_col=[0])\n",
    "match_hartford = match_adress_to_location(df_cleaned, df_geo_hartford, county=\"Hartford\")\n",
    "missing_hartford = df_hartford[~df_hartford.addr.isin(match_hartford.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_hartford = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/hartford_highway.csv\")\n",
    "df_highway_hartford = df_highway_hartford[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_hartford = df_highway_hartford.dropna(subset=\"geometry\")\n",
    "df_highway_hartford[\"geometry\"] = df_highway_hartford[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_hartford = gpd.GeoDataFrame(df_highway_hartford)\n",
    "df_highway_hartford.crs = \"EPSG:4326\"\n",
    "df_highway_hartford = df_highway_hartford.sjoin(connecticut_zip[[\"City\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_hartford = df_highway_hartford.drop(columns=[\"tiger:county\"]).rename(columns={\"name\": \"addr\", \"City\":\"city\"})\n",
    "df_highway_hartford[\"city\"] = df_highway_hartford[\"city\"].str.title()\n",
    "df_highway_hartford[\"housenr\"] = \"0\"\n",
    "\n",
    "df_geo_hartford_comb= pd.concat([df_geo_hartford, df_highway_hartford])\n",
    "missing_hartford = df_hartford[~df_hartford.addr.isin(match_hartford.addr)]\n",
    "match_hartford_2 = match_adress_to_location(missing_hartford, df_geo_hartford_comb)\n",
    "final_match_hartford = pd.concat([match_hartford, match_hartford_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match_hartford.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_hartford.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Middlesex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_middlesex = df_cleaned[df_cleaned.county == \"Middlesex\"]\n",
    "df_geo_middlesex = pd.read_csv(\"df_geo_middlesex_2.csv\", index_col=[0])\n",
    "match_middlesex = match_adress_to_location(df_cleaned, df_geo_middlesex, county=\"Middlesex\")\n",
    "missing_middlesex = df_middlesex[~df_middlesex.addr.isin(match_middlesex.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_middlesex = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/middlesex_highway.csv\")\n",
    "df_highway_middlesex = df_highway_middlesex[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_middlesex = df_highway_middlesex.dropna(subset=\"geometry\")\n",
    "df_highway_middlesex[\"geometry\"] = df_highway_middlesex[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_middlesex = gpd.GeoDataFrame(df_highway_middlesex)\n",
    "df_highway_middlesex.crs = \"EPSG:4326\"\n",
    "df_highway_middlesex = df_highway_middlesex.sjoin(connecticut_zip[[\"City\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_middlesex = df_highway_middlesex.drop(columns=[\"tiger:county\"]).rename(columns={\"name\": \"addr\", \"City\":\"city\"})\n",
    "df_highway_middlesex[\"city\"] = df_highway_middlesex[\"city\"].str.title()\n",
    "df_highway_middlesex[\"housenr\"] = \"0\"\n",
    "\n",
    "df_geo_middlesex_comb= pd.concat([df_geo_middlesex, df_highway_middlesex])\n",
    "missing_middlesex = df_middlesex[~df_middlesex.addr.isin(match_middlesex.addr)]\n",
    "match_middlesex_2 = match_adress_to_location(missing_middlesex, df_geo_middlesex_comb)\n",
    "final_match_middlesex = pd.concat([match_middlesex, match_middlesex_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fairfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairfield = df_cleaned[df_cleaned.county == \"Fairfield\"]\n",
    "df_geo_fairfield = pd.read_csv(\"df_geo_fairfield_2.csv\", index_col=[0])\n",
    "match_fairfield = match_adress_to_location(df_cleaned, df_geo_fairfield, county=\"Fairfield\")\n",
    "missing_fairfield = df_fairfield[~df_fairfield.addr.isin(match_fairfield.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highway_fairfield = pd.read_csv(\"/Volumes/Seagate/Bavillion/highway/fairfield_highway.csv\")\n",
    "df_highway_fairfield = df_highway_fairfield[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_fairfield = df_highway_fairfield.dropna(subset=\"geometry\")\n",
    "df_highway_fairfield[\"geometry\"] = df_highway_fairfield[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_fairfield = gpd.GeoDataFrame(df_highway_fairfield)\n",
    "df_highway_fairfield.crs = \"EPSG:4326\"\n",
    "df_highway_fairfield = df_highway_fairfield.sjoin(connecticut_zip[[\"City\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_fairfield = df_highway_fairfield.drop(columns=[\"tiger:county\"]).rename(columns={\"name\": \"addr\", \"City\":\"city\"})\n",
    "df_highway_fairfield[\"city\"] = df_highway_fairfield[\"city\"].str.title()\n",
    "df_highway_fairfield[\"housenr\"] = \"0\"\n",
    "\n",
    "df_geo_fairfield_comb= pd.concat([df_geo_fairfield, df_highway_fairfield])\n",
    "missing_fairfield= df_fairfield[~df_fairfield.addr.isin(match_fairfield.addr)]\n",
    "match_fairfield_2 = match_adress_to_location(missing_fairfield, df_geo_fairfield_comb)\n",
    "final_match_fairfield = pd.concat([match_fairfield, match_fairfield_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match = pd.concat([\n",
    "    final_match_fairfield,\n",
    "    final_match_fairfax,\n",
    "    final_match_hartford,\n",
    "    final_match_haven,\n",
    "    final_match_litchfield,\n",
    "    final_match_london,\n",
    "    final_match_middlesex,\n",
    "    final_match_tolland,\n",
    "    final_match_windham,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match.to_csv(\"final_match.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.DataFrame()\n",
    "counties = {\n",
    "            \"new_haven\" : \"New Haven\",\n",
    "            \"new_london\": \"New London\",\n",
    "            \"middlesex\": \"Middlesex\",\n",
    "            \"litchfield\": \"Litchfield\",\n",
    "            \"hartford\": \"Hartford\",\n",
    "            \"fairfield\": \"Fairfield\",\n",
    "            \"tolland\": \"Tolland\",\n",
    "            \"windham\": \"Windham\",\n",
    "            }\n",
    "\n",
    "for k, v in counties.items():\n",
    "    df = df_cleaned[df_cleaned.county == v]\n",
    "    df_geo = pd.read_csv(f\"df_geo_{k}_2.csv\", index_col=[0])\n",
    "    match = match_adress_to_location(df_cleaned, df_geo, county=v)\n",
    "    missing = pd.concat([missing, df[~df.addr.isin(match.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"df_geo_new_haven_2.csv\", index_col=[0])\n",
    "b = pd.read_csv(\"df_geo_new_london_2.csv\", index_col=[0])\n",
    "c = pd.read_csv(\"df_geo_middlesex_2.csv\", index_col=[0])\n",
    "d = pd.read_csv(\"df_geo_litchfield_2.csv\", index_col=[0])\n",
    "e = pd.read_csv(\"df_geo_hartford_2.csv\", index_col=[0])\n",
    "f = pd.read_csv(\"df_geo_fairfield_2.csv\", index_col=[0])\n",
    "g = pd.read_csv(\"df_geo_tolland_2.csv\", index_col=[0])\n",
    "h = pd.read_csv(\"df_geo_windham_2.csv\", index_col=[0])\n",
    "\n",
    "df = df_cleaned[df_cleaned.county != \"Fairfax\"]\n",
    "df_geo = pd.concat([a, b,c,d,e,f,g,h])\n",
    "match = match_adress_to_location(df_cleaned, df_geo)\n",
    "missing = df[~df.addr.isin(match.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
