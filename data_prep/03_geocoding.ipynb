{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Geocoding\n",
    "\n",
    "In this notebook we geocode our address data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as req\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Adjust Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_geocode(folder=\"../data/cleaned/\"):\n",
    "    df_fairfax = pd.read_csv(folder+\"df_fairfax_cleaned.csv\" ,index_col=[0])\n",
    "    df_connecticut = pd.read_csv(folder+\"df_connecticut_cleaned.csv\", index_col=[0])\n",
    "    df_fairfax_addr = df_fairfax[[\"city\", \"addr\", \"county\"]].drop_duplicates()\n",
    "    df_connecticut_addr = df_connecticut[[\"city\", \"addr\", \"county\"]].drop_duplicates()\n",
    "    df_fairfax_addr[\"state\"] = \"Virginia\"\n",
    "    df_connecticut_addr[\"state\"] = \"Connecticut\"\n",
    "    df_combined = pd.concat([df_fairfax_addr, df_connecticut_addr])\n",
    "    df_combined[\"addr\"] = df_combined.addr.str.title()\n",
    "    df_combined[\"city\"] = df_combined.city.str.title()\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_digits(street):\n",
    "    first_split = street.split(' ')[0]\n",
    "    if re.search('\\d+', first_split):\n",
    "        return ' '.join(street.split(' ')[1:])\n",
    "    else:\n",
    "        return street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(housenumber):\n",
    "    match = re.match(r'^\\d+', housenumber)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else: \n",
    "        return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_end_digits(street):\n",
    "    if \"Route\" in street:\n",
    "        return street\n",
    "    else:\n",
    "        return re.sub(r'(?:\\d+[+-]\\d*|[-+]\\d+|\\d+[A-Za-z]*)(\\s|$)', '', street)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_start_digits(street):\n",
    "    if \"Route\" in street:\n",
    "        return street\n",
    "    else:\n",
    "        return re.sub(r'(\\s|^)(?:\\d+[+-]\\d*|[-+]\\d+|\\d+[A-Za-z]*)', '', street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_the_to_front(street):\n",
    "    if re.search(r\"\\bThe\\b\", street):\n",
    "        street = re.sub(r\"\\bThe\\b\", \"\", street)\n",
    "        street = street.replace(\"()\", \"\").strip()\n",
    "        street = street.strip(\",\")\n",
    "        return \"The \" + street.strip()  \n",
    "    else:\n",
    "        return street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_split(street):\n",
    "    parts = re.split(r\"/|&|\\\\\", street)\n",
    "    if len(parts) > 1:\n",
    "        first = (parts[0]\n",
    "                .strip()\n",
    "                .strip(\"-\")\n",
    "                .strip(\".\")\n",
    "                )\n",
    "        \n",
    "        if first.isdigit() or (first == \"\"):\n",
    "            return parts[1]\n",
    "        return parts[0]\n",
    "    return street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_letters(street):\n",
    "    if re.search(r\"\\bB Lane\", street):\n",
    "        return re.sub(r\"\\b(?!')[a-zA-Z]$\", \"\", street.strip())\n",
    "    elif re.search(r\"Avenue B(\\s|$)\", street) or re.search(r\"Aaron B(\\s|$)\", street) or re.search(r\"Ave B(\\s|$)\", street):\n",
    "        return re.sub(r\"^[a-zA-Z]\\b(?!')\", \" \", street.strip())\n",
    "    else:\n",
    "        return re.sub(r\"(^)\\b(?!')[a-zA-Z]\\b(?!')|\\b(?!')[a-zA-Z]\\b(?!')($)\", '', street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_paran(street):\n",
    "    return re.sub(r'\\(.*?$', \"\", street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbrv(df_addr):\n",
    "    return (df_addr.apply(lambda x: re.sub(r\"St Joseph\", \"Saint Joseph\", x))\n",
    "                      .apply(lambda x: re.sub(r\"St($|\\b)\", \"Street \", x))\n",
    "                      .apply(lambda x: re.sub(r'\\bUnit(\\b|$)\\.*', '', x))\n",
    "                      .apply(lambda x: re.sub(r\"Ct($|\\b)\", \"Court \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Crt($|\\b)\", \"Court \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cor($|\\b)\", \"Corner \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ctr($|\\b)\", \"Center \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Av($|\\s|\\b)\", \"Avenue \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ave($|\\s|\\b)\", \"Avenue \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Apts($|\\b)\", \"Apartments \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Al($|\\b)\", \"Alley \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tr($|\\b)\", \"Terrace \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Terr($|\\b)\", \"Terrace \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Te($|\\b)\", \"Terrace \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Trce($|\\b)\", \"Trace\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Thse($|\\b)\", \"Townhouse \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pl($|\\b)\", \"Place \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Wy($|\\b)\", \"Way \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Wa($|\\b)\", \"Way \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ter($|\\b)\", \"Terrace \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Blvd($|\\b)\", \"Boulevard \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bl($|\\b)\", \"Boulevard \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bv($|\\b)\", \"Boulevard \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Blv($|\\b)\", \"Boulevard \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bch($|\\b)\", \"Beach \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cmn($|\\b)\", \"Common \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cmns($|\\b)\", \"Commons \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hol($|\\b)\", \"Hollow \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hlw($|\\b)\", \"Hollow \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Sq($|\\b)\", \"Square \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Trl($|\\b)\", \"Trail \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tl($|\\b)\", \"Trail \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hwy($|\\b)\", \"Highway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hi($|\\b)\", \"Highway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hgwy($|\\b)\", \"Highway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lndg($|\\b)\", \"Landing \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pt($|\\b)\", \"Point \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Po($|\\b)\", \"Point \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pro($|\\b)\", \"Professional \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Brk($|\\b)\", \"Brook \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rdg($|\\b)\", \"Ridge \", x))\n",
    "                      .apply(lambda x: re.sub(r\"So($|\\b)\", \"South \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tp($|\\b)\", \"Turnpike \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tpk($|\\b)\", \"Turnpike \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tpke($|\\b)\", \"Turnpike \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Tnpk($|\\b)\", \"Turnpike \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bp($|\\b)\", \"Bridgeport \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Br($|\\b)\", \"Bridge \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pkwy($|\\b)\", \"Parkway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pky($|\\b)\", \"Parkway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Vw($|\\b)\", \"View \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cv($|\\b)\", \"Cove \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ave($|\\b)\", \"Avenue \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Dr($|\\b)\", \"Drive \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cr($|\\b)\", \"Circle \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ci($|\\b)\", \"Circle \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cir($|\\b)\", \"Circle \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cl($|\\b)\", \"Close \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cswy($|\\b)\", \"Causeway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cres($|\\b)\", \"Crescent \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Se($|\\b)\", \"Southeast \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Sw($|\\b)\", \"Southwest \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Nw($|\\b)\", \"Northwest \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ne($|\\b)\", \"Northeast \", x))\n",
    "                      .apply(lambda x: re.sub(r\"No($|\\b)\", \"North \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Plz($|\\b)\", \"Plaza \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ptwy($|\\b)\", \"Pathway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pth($|\\b)\", \"Path \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Grv($|\\b)\", \"Grove \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Gr($|\\b)\", \"Grove \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Drs($|\\b)\", \"Drive \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hgts($|\\b)\", \"Heights \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hghts($|\\b)\", \"Heights \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hts($|\\b)\", \"Heights \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ht($|\\b)\", \"Heights \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hl($|\\b)\", \"Hill \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Hls($|\\b)\", \"Hills \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pk($|\\b)\", \"Park \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rdg($|\\b)\", \"Ridge \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ex($|\\b)\", \"Extension \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ext($|\\b)\", \"Extension \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rte($|\\b)\", \"Route \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rd($|\\b)\", \"Road \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rvr($|\\b)\", \"River \", x))\n",
    "                      .apply(lambda x: re.sub(r\"La($|\\b)\", \"Lane \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ln($|\\b)\", \"Lane \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ldg($|\\b)\", \"Lodge \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mtn($|\\b)\", \"Mountain \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mt($|\\b)\", \"Mountain \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ind($|\\b)\", \"Industrial \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lk($|\\b)\", \"Lake \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Vlg($|\\b)\", \"Village \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mnr($|\\b)\", \"Manor \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Knls($|\\b)\", \"Knolls \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Knl($|\\b)\", \"Knoll \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Pswy($|\\b)\", \"Passway \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Qtr($|\\b)\", \"Quarter \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mdw($|\\b)\", \"Meadow \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Vly($|\\b)\", \"Valley \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Kn($|\\b)\", \"Knoll \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Grn($|\\b)\", \"Green \", x))\n",
    "                      .apply(lambda x: re.sub(r\"Is($|\\b)\", \"Island \", x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = df.dropna(subset=\"addr\")\n",
    "    df[\"housenr\"] = df[\"addr\"].apply(lambda x:np.nan if x==np.nan else re.split(r\"\\s|/\", x)[0])\n",
    "    df[\"housenr\"] = df[\"housenr\"].apply(match)\n",
    "    df[\"addr_mod\"] = (df[\"addr\"].apply(split_digits)\n",
    "                      .str.strip(\"-\")\n",
    "                      .apply(lambda x: x if not x.strip().endswith('La') else x.replace('La', 'Lane'))\n",
    "                      .apply(lambda x: x if not x.strip().endswith('Ext') else x.replace('Ext', 'Extension'))\n",
    "                      .apply(lambda x: re.sub(r\"\\-[A-Z]$\", \"\",x))\n",
    "                      .apply(lambda x: re.sub(r\"\\s[A-Z]\\-[A-Z]\\s\", \"\",x))\n",
    "                      .str.replace(\"Rt \", \"Route \")\n",
    "                      .str.replace('No ', 'North ')\n",
    "                      .str.replace(' No ', ' North ')\n",
    "                      .str.replace('Resv ', 'Reservoir ')\n",
    "                      .str.replace(' Resv ', ' Reservoir ')\n",
    "                      .str.replace(' Rd ', ' Road ')\n",
    "                      .str.replace(' La ', ' Lane ')\n",
    "                      .str.replace('Talcott Forest Road East', 'Talcott Forest Road') #???\n",
    "                      .apply(lambda x: re.sub(r'\\bLn(\\s|$)', \"Lane \", x))\n",
    "                      .str.replace(' Tpke ', ' Turnpike ')\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)N($|\\s)\", \" North \", x))\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)W($|\\s)\", \" West \", x))\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)S($|\\s)\", \" South  \", x))\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)E($|\\s)\", \" East \", x))\n",
    "                      .apply(lambda x: re.sub(r\"(^|\\s)N W($|\\s)\", \" Northwest \", x))\n",
    "                      .apply(put_the_to_front)\n",
    "                      .apply(lambda x: re.sub(\"O Neill\", \"O'Neill\", x))\n",
    "                      .apply(lambda x: re.sub(r\"O Brien\", \"O'Brien\", x))\n",
    "                      .apply(lambda x: re.sub(r\"O Clock\", \"O'Clock\", x))\n",
    "                      .apply(lambda x: re.sub(r\"O Rocks\", \"O'Rocks\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Wells Place Place\", \"Wells Place\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Alexander D \", \"Alexander Drive \", x))\n",
    "                      .apply(remove_letters)\n",
    "                      .apply(lambda x: re.sub(r'\\(.*?\\)', \"\", x)) # remove (\"any string\")\n",
    "                      .apply(remove_end_digits)\n",
    "                      .apply(ad_split)\n",
    "                      .apply(lambda x: re.sub(r\"#\\S*\", \"\", x))\n",
    "                      .str.strip()\n",
    "                      .str.strip(\",\")\n",
    "                      .str.strip(\".\")\n",
    "                      .str.strip()\n",
    "    )\n",
    "    df[\"addr_mod\"] = abbrv(df[\"addr_mod\"])\n",
    "    df[\"addr_mod\"] = (df[\"addr_mod\"]\n",
    "                      .str.replace(\"#North\", \"North\")\n",
    "                      .str.replace(\"#South\", \"South\")\n",
    "                      .str.replace(\"#West\", \"West\")\n",
    "                      .str.replace(\"#East\", \"East\")\n",
    "                      .str.replace(\"#Wy\", \"Way\")\n",
    "                      .apply(remove_letters)\n",
    "                      .str.replace(\"- Union\", \"Union\")\n",
    "                      .str.replace(\"- Extension\", \"Extension\")\n",
    "                      .str.replace(\"-Extension\", \"Extension\")\n",
    "                      .str.replace(\"Nrwh Wstly\", \"Norwich Westerly\")\n",
    "                      .str.replace(\"Avenue-Extension\", \"Avenue Extension\")\n",
    "                      .str.replace(\"  \", \" \")\n",
    "                      .str.strip(\"_\")\n",
    "                      .str.strip()\n",
    "                      .apply(lambda x: re.sub(r\"^[\\d\\s.]*\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rear$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Re$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rea$\", \"Rear\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Gar$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lt$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Adj$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Aka$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ch$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ch2$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ctg$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ul$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Cb$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ogba$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Gnh$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bpbc$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lowr$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lp$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Om$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ply$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Preq$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lz$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rz$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Abcd$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Eb$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Prim$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Osg$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Dwl$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Iii$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ab$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Lot$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Rr$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bldg$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Beu$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Na$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ph$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Un1$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Una$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Kc$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bh$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Mr$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Prvt$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Gnb$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Bsmt$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Unit$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Aa$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Ru$\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Street Land$\", \"Street\", x)) #???\n",
    "                      .apply(remove_end_digits)\n",
    "                      .apply(remove_start_digits)\n",
    "                      .apply(lambda x: re.sub(r\"^\\d+\", \"\", x))\n",
    "                      .apply(lambda x: re.sub(r\"Oneill\", \"O'neill\", x))\n",
    "                      .apply(lambda x: re.sub(r\"\\([a-zA-Z\\d]*\\)\", \"\",x)) \n",
    "                      .apply(lambda x: re.sub(r\"^Off\\b\", \" \",x)) \n",
    "                      .apply(lambda x: re.sub(r\"^Rdwy\", \"\",x)) \n",
    "                      .apply(lambda x: re.sub(r\"^Lot\\b\", \" \",x)) \n",
    "                      .apply(lambda x: re.sub(r\"^Lot A\", \"\",x)) \n",
    "                      .apply(remove_after_paran)\n",
    "                      .str.replace(\"Fish Game\", \"Fish + Game\")\n",
    "                      .str.replace(\"Street Andrews\", \"St Andrews\")\n",
    "                      .str.replace(\"Street John\", \"St John\")\n",
    "                      .str.replace(\"Street Lawrence\", \"St Lawrence\")\n",
    "                      .str.replace(\"Street Paul\", \"St Paul\")\n",
    "                      .str.replace(\"Street Thomas\", \"St Thomas\")\n",
    "                      .str.replace(\"Street Stephens\", \"St Stephens\")\n",
    "                      .str.replace(\"Street Mathias\", \"St Stephens\")\n",
    "                      .str.replace(\"Street Andrew\", \"St Andrew\")\n",
    "                      .str.replace(\"Street James\", \"St James\")\n",
    "                      .str.strip()\n",
    "                      .str.strip(\",\")\n",
    "                      .str.strip(\"-\")\n",
    "                      .apply(remove_letters)\n",
    "                      .str.strip(\"-\")\n",
    "                      .str.strip(\",\")\n",
    "                      .str.strip(\"-\")\n",
    "                      .str.strip(\".\")\n",
    "                      .str.strip(\"+\")\n",
    "                      .str.strip()\n",
    "                      )\n",
    "    df[\"housenr\"] = np.where(df.housenr.str.isdigit(), df.housenr, np.nan)\n",
    "    return df.reset_index(drop=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_adress_to_location(df, df_geo, county=\"all\"):\n",
    "    if county!=\"all\":\n",
    "        df = df[df.county == county]\n",
    "    print(df.shape)\n",
    "    df_merge = df.merge(df_geo, how=\"left\", left_on=[\"addr_mod\", \"housenr\", \"city\"], right_on=[\"addr\", \"housenr\", \"city\"])\n",
    "    df_missings = df_merge[df_merge.geometry.isnull()]\n",
    "    df_found = df_merge.dropna(subset=[\"geometry\"]) \n",
    "    df_missings = df_merge[df_merge.geometry.isnull()]\n",
    "    df_missing_housnr = df_missings[df_missings[\"housenr\"].isnull()]\n",
    "    df_missings = df_missings.dropna(subset=\"housenr\")\n",
    "    df_missing_merge = df_missings.merge(df_geo, how=\"left\", left_on=[\"addr_mod\", \"city\"], right_on=[\"addr\", \"city\"])\n",
    "\n",
    "    df_missing_merge[\"housenr_x\"] = df_missing_merge[\"housenr_x\"].dropna().apply(lambda x: re.sub(r'[a-zA-z]', '', x)).astype(\"float64\")\n",
    "    df_missing_merge[\"housenr_y\"] = (df_missing_merge[\"housenr_y\"].dropna().apply(lambda x: x.split('-')[0])\n",
    "                                     .apply(lambda x: x.split(\"+\")[0])\n",
    "                                     .apply(lambda x: x.split(\"&\")[0])\n",
    "                                     .apply(lambda x: x.split(\";\")[0])\n",
    "                                     .apply(lambda x: x.split(\" \")[0])\n",
    "                                     .apply(lambda x: x.split(\",\")[0])\n",
    "                                     .apply(lambda x: x.split(\"/\")[0])\n",
    "                                     .str.strip(\"#\")\n",
    "                                     .str.strip(\"Ë\")\n",
    "                                     .str.replace(\")\", \"\")\n",
    "                                     .apply(lambda x: re.sub(r'[a-zA-z]', '', x)))\n",
    "    df_missing_merge[\"housenr_y\"] = np.where(df_missing_merge[\"housenr_y\"] == \"\", np.nan, df_missing_merge[\"housenr_y\"]).astype(\"float64\")\n",
    "    df_missing_merge[\"diff\"] = np.abs(df_missing_merge[\"housenr_x\"] - df_missing_merge[\"housenr_y\"])\n",
    "    df_found_2 = df_missing_merge.loc[df_missing_merge.dropna(subset=\"geometry_y\").groupby(by=[\"addr_x\", \"city\"])[\"diff\"].idxmin().dropna()]\n",
    "    df_missing_merge_h = df_missing_housnr.merge(df_geo, how=\"left\", left_on=[\"addr_mod\", \"city\"], right_on=[\"addr\", \"city\"])\n",
    "    df_missing_merge_h = df_missing_merge_h.dropna(subset=\"geometry_y\")\n",
    "    df_found_3 = df_missing_merge_h.dropna(subset=\"geometry_y\").groupby(by=[\"addr_x\", \"city\"]).sample(1)\n",
    "    selected_columns = [\"addr\", \"city\", \"county\", \"state\", \"geometry\"]\n",
    "\n",
    "    \n",
    "    df_found = df_found.rename(columns={\"geometry_y\": \"geometry\", \"addr_x\":\"addr\"})\n",
    "    df_found_2 = df_found_2.drop(columns=\"addr\").rename(columns={\"geometry_y\": \"geometry\", \"addr_x\":\"addr\"})\n",
    "    df_found_3 = df_found_3.drop(columns=\"addr\").rename(columns={\"geometry_y\": \"geometry\", \"addr_x\":\"addr\"})\n",
    "\n",
    "    df_clean = pd.concat([df_found, df_found_2, df_found_3])\n",
    "    return df_clean[selected_columns].reset_index(drop=True).drop_duplicates(subset=[\"addr\", \"city\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = load_data_to_geocode()\n",
    "df_cleaned = clean(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/2622593439.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"housenr\"] = df[\"addr\"].apply(lambda x:np.nan if x==np.nan else re.split(r\"\\s|/\", x)[0])\n",
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/2622593439.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"housenr\"] = df[\"housenr\"].apply(match)\n",
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/2622593439.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"addr_mod\"] = (df[\"addr\"].apply(split_digits)\n",
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/2622593439.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"addr_mod\"] = abbrv(df[\"addr_mod\"])\n",
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/2622593439.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"addr_mod\"] = (df[\"addr_mod\"]\n",
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/2622593439.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"housenr\"] = np.where(df.housenr.str.isdigit(), df.housenr, np.nan)\n"
     ]
    }
   ],
   "source": [
    "# clean\n",
    "df_cleaned = clean(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fairfax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fairfax = df_cleaned[df_cleaned.county == \"Fairfax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo_fairfax = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_fairfax1_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/2261432812.py:2: DtypeWarning: Columns (0,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,130,133,134,135,137,138,139,140,142,143,144,145,146,147,148,149,151,152,153,154,155,156,157,158,159,160,161,162,167,168,169,171,172,174,175,176,178,179,180,181,182,183,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,206,207,208,209,210,211,212,213,214,215,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,234,235,236,237,238,239,240,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,300,301,302,303,304,305,306,307,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,335,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,369,374,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,421,422,423,424,425,428) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_highway_fairfax = pd.read_csv(\"/Volumes/Seagate/Bavillion/geo/highway/fairfax_highway.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>addr</th>\n",
       "      <th>addr:postcode</th>\n",
       "      <th>city</th>\n",
       "      <th>housenr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LINESTRING (-77.42476 38.91490, -77.42492 38.9...</td>\n",
       "      <td>Air and Space Museum Parkway</td>\n",
       "      <td>20151.0</td>\n",
       "      <td>Chantilly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LINESTRING (-77.26545 38.86497, -77.26520 38.8...</td>\n",
       "      <td>Arlington Boulevard</td>\n",
       "      <td>22031.0</td>\n",
       "      <td>Fairfax</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINESTRING (-77.30880 38.84284, -77.30888 38.8...</td>\n",
       "      <td>Judicial Drive</td>\n",
       "      <td>22030.0</td>\n",
       "      <td>Fairfax</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LINESTRING (-77.32029 38.83755, -77.31208 38.8...</td>\n",
       "      <td>University Drive</td>\n",
       "      <td>22030.0</td>\n",
       "      <td>Fairfax</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LINESTRING (-77.29778 38.77583, -77.29402 38.7...</td>\n",
       "      <td>Lakehaven Court</td>\n",
       "      <td>22015.0</td>\n",
       "      <td>Burke</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163052</th>\n",
       "      <td>POINT (-77.36321 38.95386)</td>\n",
       "      <td>SUNSET HILLS RD @ TOWN CENTER PKWY</td>\n",
       "      <td>20190.0</td>\n",
       "      <td>Reston</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163053</th>\n",
       "      <td>POINT (-77.36478 38.95417)</td>\n",
       "      <td>SUNSET HILLS RD @ TOWN CTR PKW</td>\n",
       "      <td>20190.0</td>\n",
       "      <td>Reston</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163170</th>\n",
       "      <td>POINT (-77.14519 38.75675)</td>\n",
       "      <td>Kingstowne Village Pkwy. and Hayfield Rd.</td>\n",
       "      <td>22315.0</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163187</th>\n",
       "      <td>POINT (-77.15143 38.75349)</td>\n",
       "      <td>Kingstowne Village Pkwy. and Park Village Dr.</td>\n",
       "      <td>22315.0</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163396</th>\n",
       "      <td>POINT (-77.22777 38.87827)</td>\n",
       "      <td>WMATA</td>\n",
       "      <td>22180.0</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 geometry  \\\n",
       "1       LINESTRING (-77.42476 38.91490, -77.42492 38.9...   \n",
       "3       LINESTRING (-77.26545 38.86497, -77.26520 38.8...   \n",
       "4       LINESTRING (-77.30880 38.84284, -77.30888 38.8...   \n",
       "5       LINESTRING (-77.32029 38.83755, -77.31208 38.8...   \n",
       "7       LINESTRING (-77.29778 38.77583, -77.29402 38.7...   \n",
       "...                                                   ...   \n",
       "163052                         POINT (-77.36321 38.95386)   \n",
       "163053                         POINT (-77.36478 38.95417)   \n",
       "163170                         POINT (-77.14519 38.75675)   \n",
       "163187                         POINT (-77.15143 38.75349)   \n",
       "163396                         POINT (-77.22777 38.87827)   \n",
       "\n",
       "                                                 addr  addr:postcode  \\\n",
       "1                        Air and Space Museum Parkway        20151.0   \n",
       "3                                 Arlington Boulevard        22031.0   \n",
       "4                                      Judicial Drive        22030.0   \n",
       "5                                    University Drive        22030.0   \n",
       "7                                     Lakehaven Court        22015.0   \n",
       "...                                               ...            ...   \n",
       "163052             SUNSET HILLS RD @ TOWN CENTER PKWY        20190.0   \n",
       "163053                 SUNSET HILLS RD @ TOWN CTR PKW        20190.0   \n",
       "163170      Kingstowne Village Pkwy. and Hayfield Rd.        22315.0   \n",
       "163187  Kingstowne Village Pkwy. and Park Village Dr.        22315.0   \n",
       "163396                                          WMATA        22180.0   \n",
       "\n",
       "              city  housenr  \n",
       "1        Chantilly      NaN  \n",
       "3          Fairfax      NaN  \n",
       "4          Fairfax      NaN  \n",
       "5          Fairfax      NaN  \n",
       "7            Burke      NaN  \n",
       "...            ...      ...  \n",
       "163052      Reston      NaN  \n",
       "163053      Reston      NaN  \n",
       "163170  Alexandria      NaN  \n",
       "163187  Alexandria      NaN  \n",
       "163396      Vienna      NaN  \n",
       "\n",
       "[39570 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# geo data prep use highway data\n",
    "df_fairfax_cities = gpd.read_file(\"../data/raw/geocoding/city_boundries/fairfax_cities.geojson\", index_col=[0])\n",
    "df_highway_fairfax = pd.read_csv(\"/Volumes/Seagate/Bavillion/geo/highway/fairfax_highway.csv\")\n",
    "df_highway_fairfax = df_highway_fairfax[[\"geometry\", \"tiger:county\", \"name\"]].dropna(subset=\"name\")\n",
    "df_highway_fairfax = df_highway_fairfax.dropna(subset=\"geometry\")\n",
    "df_highway_fairfax[\"geometry\"] = df_highway_fairfax[\"geometry\"].apply(wkt.loads)\n",
    "df_highway_fairfax = gpd.GeoDataFrame(df_highway_fairfax)\n",
    "df_highway_fairfax.crs = \"EPSG:4326\"\n",
    "df_highway_fairfax = df_highway_fairfax.sjoin(df_fairfax_cities[[\"ZIPCODE\", \"ZIPCITY\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_highway_fairfax = df_highway_fairfax.drop(columns=[\"tiger:county\", \"index_right\"]).rename(columns={\"ZIPCODE\":\"addr:postcode\", \n",
    "                                \"ZIPCITY\":\"city\", \n",
    "                                \"name\": \"addr\"})\n",
    "df_highway_fairfax[\"city\"] = df_highway_fairfax[\"city\"].str.title()\n",
    "df_highway_fairfax[\"housenr\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing geo data\n",
    "df_geo_fairfax[\"geometry\"] = df_geo_fairfax[\"geometry\"].apply(wkt.loads)\n",
    "df_geo_fairfax = gpd.GeoDataFrame(df_geo_fairfax)\n",
    "df_geo_fairfax.crs = \"EPSG:4326\" \n",
    "\n",
    "df_fairfax_cities.crs = \"EPSG:4326\" \n",
    "\n",
    "df_geo_fairfax = df_geo_fairfax.sjoin(df_fairfax_cities[[\"ZIPCODE\", \"ZIPCITY\", \"geometry\"]], how=\"left\", predicate=\"intersects\")\n",
    "df_geo_fairfax = df_geo_fairfax.drop(columns=[\"city\", \"addr:postcode\"]).rename(columns={\"ZIPCODE\": \"postcode\", \"ZIPCITY\":\"city\"})\n",
    "\n",
    "df_geo_fairfax[\"city\"] = df_geo_fairfax[\"city\"].str.title()\n",
    "\n",
    "grouped_addr = df_fairfax.groupby(by=[\"addr_mod\", \"city\"]).size().to_frame()\n",
    "grouped_addr.columns = [\"size\"]\n",
    "grouped_addr = grouped_addr.reset_index()\n",
    "addr_count = grouped_addr.addr_mod.value_counts().to_frame().reset_index()\n",
    "unique_addr = addr_count[addr_count[\"count\"] == 1].addr_mod.values\n",
    "unique_addr_city = df_fairfax[df_fairfax.addr_mod.isin(unique_addr)][[\"addr_mod\", \"city\"]].drop_duplicates()\n",
    "df_geo_fairfax = df_geo_fairfax.merge(unique_addr_city, how=\"left\", left_on=\"addr\", right_on=\"addr_mod\", suffixes=[\"_geo\", \"_add\"])\n",
    "df_geo_fairfax[\"city\"] = np.where(df_geo_fairfax.city_geo.isna(), df_geo_fairfax.city_add, df_geo_fairfax.city_geo)\n",
    "df_geo_fairfax = df_geo_fairfax.drop(columns=[\"city_geo\", \"city_add\", \"addr_mod\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split(postcode):\n",
    "    if isinstance(postcode, float) and np.isnan(postcode):\n",
    "        return postcode\n",
    "    return postcode.split(\"-\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many are matched on whole address data\n",
    "df_merge = df_fairfax.merge(df_geo_fairfax, how=\"left\", left_on=[\"addr_mod\", \"housenr\", \"city\"], right_on=[\"addr\", \"housenr\", \"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_match = pd.read_csv(\"../data/cleaned/final_match.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Windham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecticut_zip = gpd.read_file(\"../data/raw/geocoding/city_boundries/ct_connecticut_zip_codes_geo.min.json\")\n",
    "connecticut_city = pd.read_csv(\"../data/raw/geocoding/city_boundries/ct_zipcode_city.csv\")\n",
    "connecticut_zip = connecticut_zip[[\"ZCTA5CE10\", \"geometry\"]]\n",
    "connecticut_city = connecticut_city[[\"zip\", \"City\"]]\n",
    "connecticut_city = connecticut_city.dropna(subset=\"City\")\n",
    "connecticut_zip = connecticut_zip.rename(columns={\"ZCTA5CE10\":\"zip\"})\n",
    "connecticut_zip[\"zip\"] = connecticut_zip.zip.str.lstrip(\"0\")\n",
    "connecticut_zip = connecticut_zip.merge(connecticut_city, how=\"left\", on=\"zip\")\n",
    "connecticut_zip[\"City\"] = connecticut_zip.City.str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windham = df_cleaned[df_cleaned.county == \"Windham\"]\n",
    "df_geo_windham = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_windham_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2888, 9)\n",
      "(2739, 9)\n",
      "(2704, 6)\n"
     ]
    }
   ],
   "source": [
    "# find how many are matched on whole address data\n",
    "df_merge = df_windham.merge(df_geo_windham, how=\"left\", left_on=[\"addr_mod\", \"housenr\", \"city\"], right_on=[\"addr\", \"housenr\", \"city\"])\n",
    "print(df_merge.shape)\n",
    "print(df_merge.dropna(subset=\"geometry\").shape)\n",
    "df_final_match = pd.read_csv(\"../data/cleaned/final_match.csv\")\n",
    "print(df_final_match[df_final_match.county == \"Windham\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many are matched on whole address data\n",
    "def get_match_numbers(county, df, df_geo):\n",
    "    df_merge = df.merge(df_geo, how=\"left\", left_on=[\"addr_mod\", \"housenr\", \"city\"], right_on=[\"addr\", \"housenr\", \"city\"])\n",
    "    df_merge = df_merge.drop_duplicates(subset=[\"addr_x\", \"county\", \"housenr\"])\n",
    "    print(df.shape)\n",
    "    print(df_merge.dropna(subset=\"geometry\").shape)\n",
    "    df_final_match = pd.read_csv(\"../data/cleaned/final_match.csv\")\n",
    "    print(df_final_match[df_final_match.county == county].shape[0] - df_merge.dropna(subset=\"geometry\").shape[0])\n",
    "    print(df_final_match[df_final_match.county == county].shape[0] - df_merge.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tolland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tolland = df_cleaned[df_cleaned.county == \"Tolland\"]\n",
    "df_geo_tolland = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_tolland_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22187, 9)\n",
      "(13651, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6383\n",
      "-2153\n"
     ]
    }
   ],
   "source": [
    "# find how many are matched on whole address data\n",
    "df_merge = df_tolland.merge(df_geo_tolland, how=\"left\", left_on=[\"addr_mod\", \"housenr\", \"city\"], right_on=[\"addr\", \"housenr\", \"city\"])\n",
    "print(df_merge.shape)\n",
    "print(df_merge.dropna(subset=\"geometry\").shape)\n",
    "df_final_match = pd.read_csv(\"../data/cleaned/final_match.csv\")\n",
    "print(df_final_match[df_final_match.county == \"Tolland\"].shape[0] - df_merge.dropna(subset=\"geometry\").shape[0])\n",
    "print(df_final_match[df_final_match.county == \"Tolland\"].shape[0] - df_merge.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22162, 6)\n",
      "(13561, 9)\n",
      "6473\n",
      "-2049\n"
     ]
    }
   ],
   "source": [
    "# find how many are matched on whole address data\n",
    "df_merge = df_tolland.merge(df_geo_tolland, how=\"left\", left_on=[\"addr_mod\", \"housenr\", \"city\"], right_on=[\"addr\", \"housenr\", \"city\"])\n",
    "df_merge = df_merge.drop_duplicates(subset=[\"addr_x\", \"county\", \"housenr\"])\n",
    "print(df_tolland.shape)\n",
    "print(df_merge.dropna(subset=\"geometry\").shape)\n",
    "df_final_match = pd.read_csv(\"../data/cleaned/final_match.csv\")\n",
    "print(df_final_match[df_final_match.county == \"Tolland\"].shape[0] - df_merge.dropna(subset=\"geometry\").shape[0])\n",
    "print(df_final_match[df_final_match.county == \"Tolland\"].shape[0] - df_merge.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_london = df_cleaned[df_cleaned.county == \"New London\"]\n",
    "df_geo_london = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_new_london_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New Haven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_haven = df_cleaned[df_cleaned.county == \"New Haven\"]\n",
    "df_geo_haven = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_new_haven_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154534, 6)\n",
      "(125557, 9)\n",
      "26448\n",
      "861\n"
     ]
    }
   ],
   "source": [
    "get_match_numbers(\"New Haven\", df_new_haven, df_geo_haven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Litchfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_litchfield = df_cleaned[df_cleaned.county == \"Litchfield\"]\n",
    "df_geo_litchfield = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_litchfield_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36260, 6)\n",
      "(31700, 9)\n",
      "3822\n",
      "-369\n"
     ]
    }
   ],
   "source": [
    "get_match_numbers(\"Litchfield\", df_litchfield, df_geo_litchfield)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hartford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/1215722233.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_geo_hartford = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_hartford_2.csv\", index_col=[0])\n"
     ]
    }
   ],
   "source": [
    "df_hartford = df_cleaned[df_cleaned.county == \"Hartford\"]\n",
    "df_geo_hartford = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_hartford_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157825, 6)\n",
      "(136549, 9)\n",
      "17704\n",
      "-1344\n"
     ]
    }
   ],
   "source": [
    "get_match_numbers(\"Hartford\", df_hartford, df_geo_hartford)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Middlesex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_middlesex = df_cleaned[df_cleaned.county == \"Middlesex\"]\n",
    "df_geo_middlesex = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_middlesex_2.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5246, 6)\n",
      "(4697, 9)\n",
      "461\n",
      "-88\n"
     ]
    }
   ],
   "source": [
    "get_match_numbers(\"Middlesex\", df_middlesex, df_geo_middlesex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fairfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/yj3xbk4s1t34gtb89jtxcmcr0000gn/T/ipykernel_45925/949862202.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_geo_fairfield = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_fairfield_2.csv\", index_col=[0])\n"
     ]
    }
   ],
   "source": [
    "df_fairfield = df_cleaned[df_cleaned.county == \"Fairfield\"]\n",
    "df_geo_fairfield = pd.read_csv(\"../data/raw/geocoding/houses_geocoordinates/df_geo_fairfield_2.csv\", index_col=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130884, 6)\n",
      "(113600, 9)\n",
      "16028\n",
      "-161\n"
     ]
    }
   ],
   "source": [
    "get_match_numbers(\"Fairfield\", df_fairfield, df_geo_fairfield)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match = pd.concat([\n",
    "    final_match_fairfield,\n",
    "    final_match_fairfax,\n",
    "    final_match_hartford,\n",
    "    final_match_haven,\n",
    "    final_match_litchfield,\n",
    "    final_match_london,\n",
    "    final_match_middlesex,\n",
    "    final_match_tolland,\n",
    "    final_match_windham,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match.to_csv(\"final_match.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.DataFrame()\n",
    "counties = {\n",
    "            \"new_haven\" : \"New Haven\",\n",
    "            \"new_london\": \"New London\",\n",
    "            \"middlesex\": \"Middlesex\",\n",
    "            \"litchfield\": \"Litchfield\",\n",
    "            \"hartford\": \"Hartford\",\n",
    "            \"fairfield\": \"Fairfield\",\n",
    "            \"tolland\": \"Tolland\",\n",
    "            \"windham\": \"Windham\",\n",
    "            }\n",
    "\n",
    "for k, v in counties.items():\n",
    "    df = df_cleaned[df_cleaned.county == v]\n",
    "    df_geo = pd.read_csv(f\"df_geo_{k}_2.csv\", index_col=[0])\n",
    "    match = match_adress_to_location(df_cleaned, df_geo, county=v)\n",
    "    missing = pd.concat([missing, df[~df.addr.isin(match.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"df_geo_new_haven_2.csv\", index_col=[0])\n",
    "b = pd.read_csv(\"df_geo_new_london_2.csv\", index_col=[0])\n",
    "c = pd.read_csv(\"df_geo_middlesex_2.csv\", index_col=[0])\n",
    "d = pd.read_csv(\"df_geo_litchfield_2.csv\", index_col=[0])\n",
    "e = pd.read_csv(\"df_geo_hartford_2.csv\", index_col=[0])\n",
    "f = pd.read_csv(\"df_geo_fairfield_2.csv\", index_col=[0])\n",
    "g = pd.read_csv(\"df_geo_tolland_2.csv\", index_col=[0])\n",
    "h = pd.read_csv(\"df_geo_windham_2.csv\", index_col=[0])\n",
    "\n",
    "df = df_cleaned[df_cleaned.county != \"Fairfax\"]\n",
    "df_geo = pd.concat([a, b,c,d,e,f,g,h])\n",
    "match = match_adress_to_location(df_cleaned, df_geo)\n",
    "missing = df[~df.addr.isin(match.addr)][[\"addr_mod\", \"addr\", \"city\", \"county\"]].drop_duplicates(subset=\"addr_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
