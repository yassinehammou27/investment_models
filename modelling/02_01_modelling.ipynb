{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Modelling (Models, Features, Data Splits, Loss Functions)\n",
    "\n",
    "In this notebook, we test different models, data splits, features and loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/df_train.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"data/df_test.csv\", index_col=0)\n",
    "df_val = pd.read_csv(\"data/df_val.csv\", index_col=0)\n",
    "\n",
    "\n",
    "df_train_2 = pd.read_csv(\"data/df_train_2.csv\", index_col=0)\n",
    "df_test_2 = pd.read_csv(\"data/df_test_2.csv\", index_col=0)\n",
    "df_val_2 = pd.read_csv(\"data/df_val_2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"price\", \"id\"])\n",
    "X_val = df_val.drop(columns=[\"price\", \"id\"])\n",
    "X_test = df_test.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "y_train = df_train.loc[:, \"price\"]\n",
    "y_val = df_val.loc[:, \"price\"]\n",
    "y_test = df_test.loc[:, \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = df_train_2.drop(columns=[\"price\", \"id\"])\n",
    "X_test_2 = df_test_2.drop(columns=[\"price\", \"id\"])\n",
    "X_val_2 = df_val_2.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "y_train_2 = df_train_2.loc[:, \"price\"]\n",
    "y_test_2 = df_test_2.loc[:, \"price\"]\n",
    "y_val_2 = df_val_2.loc[:, \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some loss functions\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return np.mean(200 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    epsilon = 1e-6  # Small constant to avoid division by zero\n",
    "    return np.sqrt(np.mean(((y_true - y_pred) / (y_true + epsilon)) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "model = XGBRegressor()\n",
    "param_grid = {\n",
    "    'max_depth': [8, 10, 12],\n",
    "    'learning_rate': [0.5, 0.1, 0.01],\n",
    "    'n_estimators': [300, 400, 450]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring=\"neg_mean_squared_error\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manuell \n",
    "# best combinations:\n",
    "# 1. n_estimator: 300, learning_rate:0.2, max_depth: 10\n",
    "# 2. n_estimator: 500, learning_rate:0.1, max_depth: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "y_hat = model.predict(X_val_2)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "y_hat = model.predict(X_val_2)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_val)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_2), columns=X_train_2.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_2), columns=X_test_2.columns)\n",
    "X_val_scaled = pd.DataFrame(scaler.transform(X_val_2), columns=X_val_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "print(\"Linear Regression\")\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_model.fit(X_train_scaled, y_train_2)\n",
    "y_hat = linear_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "print(\"Decision Tree Regressor\")\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "\n",
    "dt_model.fit(X_train_2, y_train_2)\n",
    "y_hat = dt_model.predict(X_val_2)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Regressor\")\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf_model.fit(X_train_2, y_train_2)\n",
    "y_hat = rf_model.predict(X_val_2)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Boosting Regressor\")\n",
    "gb_model = GradientBoostingRegressor(n_estimators=350, learning_rate=0.1, max_depth=10, random_state=42)\n",
    "\n",
    "gb_model.fit(X_train_2, y_train_2)\n",
    "y_hat = gb_model.predict(X_val_2)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_core = ['city', 'yrblt', 'effyrblt', 'nbed', 'nbath', 'nhalfbath', 'county_Fairfax', 'county_Fairfield',\n",
    "       'county_Hartford', 'county_Litchfield', 'county_Middlesex',\n",
    "       'county_New Haven', 'county_New London', 'county_Tolland',\n",
    "       'county_Windham', 'state_Connecticut', 'state_Virginia',\n",
    "       'cond_desc_Average', 'cond_desc_Average Plus', 'cond_desc_Fair',\n",
    "       'cond_desc_Good', 'cond_desc_Poor', 'year', 'month', 'age', 'eff_age', 'livarea', 'efflivarea', 'longitude', 'latitude']\n",
    "features_geo_distance = [ 'distance_aerodrome', 'distance_ferry_terminal',\n",
    "       'distance_railway_station', 'distance_market', 'distance_hospital',\n",
    "       'distance_hotel', 'distance_museum']\n",
    "features_geo_frequency = ['n_reli_inst', 'n_edu_fac',\n",
    "       'n_healthcare', 'n_emergency', 'n_animalcare', 'n_commu_venu',\n",
    "       'n_commu_serv', 'n_shopping', 'n_food_drink', 'n_financial',\n",
    "       'n_transport', 'n_entertainment', 'n_adults_entertain', 'n_sports',\n",
    "       'n_utilities', 'n_accommodation', 'n_government_civic',\n",
    "       'n_recreational']\n",
    "features_econ = ['hpi', 'household_income',\n",
    "       'new_housing', 'population', 'n_poverty', 'poverty_rate',\n",
    "       'poverty_rate_young', 'n_poverty_young', 'n_unemployed',\n",
    "       'unemployment_rate', 'civilian_labour', 'n_employed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_core = X_train_2[features_core]\n",
    "X_test_core = X_test_2[features_core]\n",
    "X_val_core = X_val_2[features_core]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_core, y_train_2)\n",
    "y_hat = model.predict(X_val_core)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geo_dist = X_train_2[features_core + features_geo_distance]\n",
    "X_test_geo_dist = X_test_2[features_core + features_geo_distance]\n",
    "X_val_geo_dist = X_val_2[features_core + features_geo_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_geo_dist, y_train_2)\n",
    "y_hat = model.predict(X_val_geo_dist)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_econ = X_train_2[features_core + features_econ]\n",
    "X_test_econ = X_test_2[features_core + features_econ]\n",
    "X_val_econ = X_val_2[features_core + features_econ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_econ, y_train_2)\n",
    "y_hat = model.predict(X_val_econ)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geo_freq = X_train_2[features_core + features_geo_frequency]\n",
    "X_test_geo_freq = X_test_2[features_core + features_geo_frequency]\n",
    "X_val_geo_freq = X_val_2[features_core + features_geo_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_geo_freq, y_train_2)\n",
    "y_hat = model.predict(X_val_geo_freq)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geo = X_train_2[features_core + features_geo_frequency + features_geo_distance]\n",
    "X_test_geo = X_test_2[features_core + features_geo_frequency + features_geo_distance]\n",
    "X_val_geo = X_val_2[features_core + features_geo_frequency + features_geo_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_geo, y_train_2)\n",
    "y_hat = model.predict(X_val_geo)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "y_hat = model.predict(X_val_2)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val_2, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe_obj(y_pred, y_train):\n",
    "    epsilon = 1e-6  # Small constant to avoid division by zero\n",
    "    grad = -2 * (y_train - y_pred) / (y_train ** 2 + epsilon)\n",
    "    hess = 2 / (y_train ** 2 + epsilon)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_pred, y_val):\n",
    "    # l(y_val, y_pred) = (y_val-y_pred)**2\n",
    "    grad = 2*(y_val-y_pred)\n",
    "    hess = np.repeat(2,y_val.shape[0])\n",
    "    return grad, hess  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_loss(y_pred, y_val):\n",
    "    # f(y_val) = abs(y_val-y_pred)\n",
    "    grad = np.sign(y_val-y_pred)*np.repeat(1,y_val.shape[0])\n",
    "    hess = np.repeat(0,y_val.shape[0])\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_huber_loss(y_pred, y_val):\n",
    "    d = (y_val-y_pred)\n",
    "    delta = 1  \n",
    "    scale = 1 + (d / delta) ** 2\n",
    "    scale_sqrt = np.sqrt(scale)\n",
    "    grad = d / scale_sqrt \n",
    "    hess = (1 / scale) / scale_sqrt\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic(y_pred, y_val):\n",
    "    # f(y_val) = (y_val-y_pred)**4\n",
    "    grad = 4*(y_val - y_pred)**3\n",
    "    hess = 12*(y_val - y_pred)**2\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return np.mean(200 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    epsilon = 1e-6  # Small constant to avoid division by zero\n",
    "    return np.sqrt(np.mean(((y_true - y_pred) / (y_true + epsilon)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": mse_loss,\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_val)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": rmspe_obj,\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_val)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": mae_loss,\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_val)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": pseudo_huber_loss,\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_val)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": cubic,\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_val)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_core = ['city', 'yrblt', 'effyrblt', 'nbed', 'nbath', 'nhalfbath', 'county_Fairfax', 'county_Fairfield',\n",
    "       'county_Hartford', 'county_Litchfield', 'county_Middlesex',\n",
    "       'county_New Haven', 'county_New London', 'county_Tolland',\n",
    "       'county_Windham', 'state_Connecticut', 'state_Virginia',\n",
    "       'cond_desc_Average', 'cond_desc_Average Plus', 'cond_desc_Fair',\n",
    "       'cond_desc_Good', 'cond_desc_Poor', 'year', 'month', 'age', 'eff_age', 'longitude', 'latitude']\n",
    "features_geo_distance = [ 'distance_aerodrome', 'distance_ferry_terminal',\n",
    "       'distance_railway_station', 'distance_market', 'distance_hospital',\n",
    "       'distance_hotel', 'distance_museum']\n",
    "features_geo_frequency = ['n_reli_inst', 'n_edu_fac',\n",
    "       'n_healthcare', 'n_emergency', 'n_animalcare', 'n_commu_venu',\n",
    "       'n_commu_serv', 'n_shopping', 'n_food_drink', 'n_financial',\n",
    "       'n_transport', 'n_entertainment', 'n_adults_entertain', 'n_sports',\n",
    "       'n_utilities', 'n_accommodation', 'n_government_civic',\n",
    "       'n_recreational']\n",
    "features_econ = ['hpi', 'household_income',\n",
    "       'new_housing', 'population', 'n_poverty', 'poverty_rate',\n",
    "       'poverty_rate_young', 'n_poverty_young', 'n_unemployed',\n",
    "       'unemployment_rate', 'civilian_labour', 'n_employed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_core = X_train_2[features_core]\n",
    "X_test_core = X_test_2[features_core]\n",
    "X_val_core = X_val_2[features_core]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_core, y_train_2)\n",
    "y_hat = model.predict(X_val_core)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "##print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geo_dist = X_train_2[features_core + features_geo_distance]\n",
    "X_test_geo_dist = X_test_2[features_core + features_geo_distance]\n",
    "X_val_geo_dist = X_val_2[features_core + features_geo_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_geo_dist, y_train_2)\n",
    "y_hat = model.predict(X_val_geo_dist)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "##print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_econ = X_train_2[features_core + features_econ]\n",
    "X_test_econ = X_test_2[features_core + features_econ]\n",
    "X_val_econ = X_val_2[features_core + features_econ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_econ, y_train_2)\n",
    "y_hat = model.predict(X_val_econ)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "##print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geo_freq = X_train_2[features_core + features_geo_frequency]\n",
    "X_test_geo_freq = X_test_2[features_core + features_geo_frequency]\n",
    "X_val_geo_freq = X_val_2[features_core + features_geo_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_geo_freq, y_train_2)\n",
    "y_hat = model.predict(X_val_geo_freq)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "##print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_geo = X_train_2[features_core + features_geo_frequency + features_geo_distance]\n",
    "X_test_geo = X_test_2[features_core + features_geo_frequency + features_geo_distance]\n",
    "X_val_geo = X_val_2[features_core + features_geo_frequency + features_geo_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_geo, y_train_2)\n",
    "y_hat = model.predict(X_val_geo)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "##print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":100,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":6,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "y_hat = model.predict(X_val_2)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val_2, y_pred=y_hat)}\")\n",
    "##print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "#print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
