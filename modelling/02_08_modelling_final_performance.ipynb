{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Modelling (Final Performance)\n",
    "\n",
    "In this notebook, we test our model architecture on unseen data (on the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv(\"data/after_pca_clustering/df_train.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"data/after_pca_clustering/df_test.csv\", index_col=0)\n",
    "df_val = pd.read_csv(\"data/after_pca_clustering/df_val.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"price\"])\n",
    "X_test = df_test.drop(columns=[\"price\"])\n",
    "X_val = df_val.drop(columns=[\"price\"])\n",
    "\n",
    "y_train = df_train.loc[:, \"price\"]\n",
    "y_test = df_test.loc[:, \"price\"]\n",
    "y_val = df_val.loc[:, \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.concat([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some loss functions\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return np.mean(200 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    epsilon = 1e-6  # Small constant to avoid division by zero\n",
    "    return np.sqrt(np.mean(((y_true - y_pred) / (y_true + epsilon)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 39282358776.85899\n",
      "MAE: 59284.11326224095\n",
      "MAPE: 22.727785816312032\n",
      "R2: 0.813105858412319\n",
      "RMSE: 198197.7769220911\n",
      "SMAPE: 15.676415337325084\n",
      "RMSPE: 1271.9488852125667\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_test, y_pred=y_hat)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering of Residual Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = model.predict(X_train) - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['longitude', 'latitude', 'county_Fairfax', 'county_Fairfield',\n",
    "       'county_Hartford', 'county_Litchfield', 'county_Middlesex',\n",
    "       'county_New Haven', 'county_New London', 'county_Tolland',\n",
    "       'county_Windham', 'state_Connecticut', 'state_Virginia',\n",
    "       'cond_desc_Average', 'cond_desc_Average Plus', 'cond_desc_Fair',\n",
    "       'cond_desc_Good', 'cond_desc_Poor']\n",
    "columns = list(set(X_train.columns) & set(columns))\n",
    "X_train_2 = X_train.rename(columns={0:\"c_0\", 1:\"c_1\", 2:\"c_2\", 3:\"c_3\", 4:\"c_4\",5:\"c_5\"})\n",
    "X_test_2 = X_test.rename(columns={0:\"c_0\", 1:\"c_1\", 2:\"c_2\", 3:\"c_3\", 4:\"c_4\",5:\"c_5\"})\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_train_2.drop(columns=columns)\n",
    "X_test_scaled = X_test_2.drop(columns=columns)\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_scaled), columns=X_train_scaled.columns, index=X_train_scaled.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_scaled), columns=X_test_scaled.columns, index=X_test_scaled.index)\n",
    "X_train_scaled = pd.concat([X_train.loc[:, columns], X_train_scaled], axis=1)\n",
    "X_test_scaled = pd.concat([X_test.loc[:, columns], X_test_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_residuals = scaler.fit_transform(residual.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled[\"residuals\"] = scaled_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 4 # You can choose the number of clusters based on your analysis\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train_scaled.drop(columns=\"residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=6)\n",
    "model.fit(X_train_scaled, clusters)\n",
    "test_labels = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = X_train_2.copy()\n",
    "X_test_3 = X_test_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3[\"cluster\"] = clusters\n",
    "X_test_3[\"cluster\"] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cl0 = X_train_3[X_train_3.cluster == 0].drop(columns=\"cluster\")\n",
    "X_test_cl0 = X_test_3[X_test_3.cluster == 0].drop(columns=\"cluster\")\n",
    "\n",
    "y_train_cl0 = y_train[X_train_cl0.index]\n",
    "y_test_cl0 = y_test[X_test_cl0.index]\n",
    "\n",
    "X_train_cl1 = X_train_3[X_train_3.cluster == 1].drop(columns=\"cluster\")\n",
    "X_test_cl1 = X_test_3[X_test_3.cluster == 1].drop(columns=\"cluster\")\n",
    "\n",
    "y_train_cl1 = y_train[X_train_cl1.index]\n",
    "y_test_cl1 = y_test[X_test_cl1.index]\n",
    "\n",
    "\n",
    "X_train_cl2 = X_train_3[X_train_3.cluster == 2].drop(columns=\"cluster\")\n",
    "X_test_cl2 = X_test_3[X_test_3.cluster == 2].drop(columns=\"cluster\")\n",
    "\n",
    "y_train_cl2 = y_train[X_train_cl2.index]\n",
    "y_test_cl2 = y_test[X_test_cl2.index]\n",
    "\n",
    "X_train_cl3 = X_train_3[X_train_3.cluster == 3].drop(columns=\"cluster\")\n",
    "X_test_cl3 = X_test_3[X_test_3.cluster == 3].drop(columns=\"cluster\")\n",
    "\n",
    "y_train_cl3 = y_train[X_train_cl3.index]\n",
    "y_test_cl3 = y_test[X_test_cl3.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 52570086096.83933\n",
      "MAE: 75458.07490421548\n",
      "MAPE: 40.960817706423676\n",
      "R2: 0.5123273426697197\n",
      "RMSE: 229281.67414086833\n",
      "SMAPE: 25.176234733422266\n",
      "RMSPE: 1126.339366104452\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.11,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_cl0, y_train_cl0)\n",
    "y_hat_0 = model.predict(X_test_cl0) \n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_test_cl0, y_pred=y_hat_0)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_test_cl0, y_pred=y_hat_0)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_test_cl0, y_pred=y_hat_0)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_test_cl0, y_pred=y_hat_0)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_test_cl0, y_pred=y_hat_0)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_test_cl0, y_pred=y_hat_0)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_test_cl0, y_pred=y_hat_0)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 68049365536.2117\n",
      "MAE: 78419.31471793672\n",
      "MAPE: 27.604819756689235\n",
      "R2: 0.7850959518782324\n",
      "RMSE: 260862.73313030304\n",
      "SMAPE: 19.885085566096663\n",
      "RMSPE: 1169.0654057556467\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_cl1, y_train_cl1)\n",
    "y_hat_1 = model.predict(X_test_cl1) \n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_test_cl1, y_pred=y_hat_1)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_test_cl1, y_pred=y_hat_1)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_test_cl1, y_pred=y_hat_1)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_test_cl1, y_pred=y_hat_1)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_test_cl1, y_pred=y_hat_1)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_test_cl1, y_pred=y_hat_1)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_test_cl1, y_pred=y_hat_1)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 114466412367.38861\n",
      "MAE: 97387.93432592026\n",
      "MAPE: 199.78499143117986\n",
      "R2: 0.7412816244335212\n",
      "RMSE: 338328.8524016073\n",
      "SMAPE: 28.507830151730868\n",
      "RMSPE: 5994.235803674219\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":400,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":7,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_cl2, y_train_cl2)\n",
    "y_hat_2 = model.predict(X_test_cl2) \n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_test_cl2, y_pred=y_hat_2)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_test_cl2, y_pred=y_hat_2)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_test_cl2, y_pred=y_hat_2)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_test_cl2, y_pred=y_hat_2)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_test_cl2, y_pred=y_hat_2)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_test_cl2, y_pred=y_hat_2)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_test_cl2, y_pred=y_hat_2)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 7090395821.474136\n",
      "MAE: 40203.4389293014\n",
      "MAPE: 0.10191687443070946\n",
      "R2: 0.9412278625212546\n",
      "RMSE: 84204.48813141813\n",
      "SMAPE: 9.911839084581963\n",
      "RMSPE: 0.1749490518025319\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":400,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":5,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_cl3, y_train_cl3)\n",
    "y_hat_3 = model.predict(X_test_cl3) \n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_test_cl3, y_pred=y_hat_3)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_test_cl3, y_pred=y_hat_3)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_test_cl3, y_pred=y_hat_3)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_test_cl3, y_pred=y_hat_3)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_test_cl3, y_pred=y_hat_3)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_test_cl3, y_pred=y_hat_3)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_test_cl3, y_pred=y_hat_3)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_cl = np.concatenate([y_hat_0, y_hat_1, y_hat_2, y_hat_3])\n",
    "y_test_cl = np.concatenate([y_test_cl0, y_test_cl1, y_test_cl2, y_test_cl3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 39454083894.079544\n",
      "MAE: 60759.09045494535\n",
      "MAPE: 22.802638455730882\n",
      "R2: 0.8122888397970599\n",
      "RMSE: 198630.52105373822\n",
      "SMAPE: 16.028900486293487\n",
      "RMSPE: 1447.657280308212\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSE: {mean_squared_error(y_true=y_test_cl, y_pred=y_hat_cl)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_test_cl, y_pred=y_hat_cl)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_test_cl, y_pred=y_hat_cl)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_test_cl, y_pred=y_hat_cl)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_test_cl, y_pred=y_hat_cl)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_test_cl, y_pred=y_hat_cl)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_test_cl, y_pred=y_hat_cl)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Regular Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 41315527756.182846\n",
      "MAE: 59566.71324610917\n",
      "MAPE: 22.063876907784053\n",
      "R2: 0.8034326263833584\n",
      "RMSE: 203262.21428534828\n",
      "SMAPE: 15.603445444726134\n",
      "RMSPE: 1230.294791320309\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/df_train_2.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"data/df_test_2.csv\", index_col=0)\n",
    "df_val = pd.read_csv(\"data/df_val_2.csv\", index_col=0)\n",
    "X_train = df_train.drop(columns=[\"price\", \"id\"])\n",
    "X_val = df_val.drop(columns=[\"price\", \"id\"])\n",
    "X_test = df_test.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "y_train = df_train.loc[:, \"price\"]\n",
    "y_val = df_val.loc[:, \"price\"]\n",
    "y_test = df_test.loc[:, \"price\"]\n",
    "\n",
    "X_train = pd.concat([X_train, X_val])\n",
    "y_train = pd.concat([y_train, y_val])\n",
    "\n",
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_test, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_test, y_pred=y_hat)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
