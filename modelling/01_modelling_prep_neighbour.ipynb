{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Modelling Prep (Neighborhood Prices)\n",
    "\n",
    "In this notebook, we calculate an additional feature: the past sale prices in the neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "import time\n",
    "import h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/df_train_2.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"data/df_test_2.csv\", index_col=0)\n",
    "df_val = pd.read_csv(\"data/df_val_2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"price\", \"id\"])\n",
    "X_test = df_test.drop(columns=[\"price\", \"id\"])\n",
    "X_val = df_val.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "y_train_2 = df_train.loc[:, \"price\"]\n",
    "y_test_2 = df_test.loc[:, \"price\"]\n",
    "y_val_2 = df_val.loc[:, \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some loss functions\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return np.mean(200 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    epsilon = 1e-6  # Small constant to avoid division by zero\n",
    "    return np.sqrt(np.mean(((y_true - y_pred) / (y_true + epsilon)) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get past sale price of neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"id\", 'city', 'longitude', 'latitude', 'year','month', \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_f = df_train[columns]\n",
    "df_test_f = df_test[columns]\n",
    "df_val_f = df_val[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame\n",
    "gdf_train = gpd.GeoDataFrame(\n",
    "    df_train_f, \n",
    "    geometry=gpd.points_from_xy(df_train_f.longitude, df_train_f.latitude)\n",
    ")\n",
    "gdf_train.set_crs(epsg=4326, inplace=True)\n",
    "gdf_train[\"geometry\"] = gdf_train.geometry.to_crs(\"EPSG:3857\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame\n",
    "gdf_test = gpd.GeoDataFrame(\n",
    "    df_test_f, \n",
    "    geometry=gpd.points_from_xy(df_test_f.longitude, df_test_f.latitude)\n",
    ")\n",
    "gdf_test.set_crs(epsg=4326, inplace=True)\n",
    "gdf_test[\"geometry\"] = gdf_test.geometry.to_crs(\"EPSG:3857\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_val = gpd.GeoDataFrame(\n",
    "    df_val_f, \n",
    "    geometry=gpd.points_from_xy(df_val_f.longitude, df_val_f.latitude)\n",
    ")\n",
    "gdf_val.set_crs(epsg=4326, inplace=True)\n",
    "gdf_val[\"geometry\"] = gdf_val.geometry.to_crs(\"EPSG:3857\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_sale_price(df, x):\n",
    "    df_tmp = df.loc[(df.id != x.id)]\n",
    "    df_tmp = df_tmp.loc[(df.year.isin([x.year-1, x.year-2]))  & (df.city == x.city)]\n",
    "    df_tmp[\"distance\"] = df_tmp.geometry.centroid.distance(x.geometry)\n",
    "    df_tmp = df_tmp.sort_values(by=[\"distance\", \"year\"])\n",
    "    return df_tmp.head(5).price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_sale_price(df, x):\n",
    "    # Filter the DataFrame for relevant rows\n",
    "    df_tmp = df.loc[(df.id != x.id) & (df.year < x.year) & (df.city == x.city)]\n",
    "    \n",
    "    if df_tmp.shape[0] == 0:\n",
    "        return 0\n",
    "    # Calculate the distances and get the smallest 5 distances directly\n",
    "    df_tmp['distance'] = df_tmp.geometry.centroid.apply(lambda geom: geom.distance(x.geometry))\n",
    "    df_tmp = df_tmp.nsmallest(5, columns=['distance', 'year'])\n",
    "\n",
    "    return df_tmp.price.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_sale_price_2(df, x, radius=1500):\n",
    "    df_tmp = df.loc[(df.id != x.id)]\n",
    "    df_tmp = df_tmp.loc[(df.year.isin([x.year-1, x.year-2, x.year-3, x.year-5, x.year-6]))  & (df.city == x.city)]\n",
    "    buffer = x.geometry.buffer(radius)\n",
    "    points_within = df_tmp.intersects(buffer)\n",
    "    return points_within.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_sale_price_2(df, x, radius=1500):\n",
    "    # Combine filtering steps into one operation\n",
    "    df_filtered = df[(df.id != x.id) & \n",
    "                     (df.year.isin([x.year-1, x.year-2, x.year-3, x.year-5, x.year-6])) & \n",
    "                     (df.city == x.city)]\n",
    "    \n",
    "    # Buffer calculation\n",
    "    buffer = x.geometry.buffer(radius)\n",
    "    \n",
    "    # Efficient spatial operation to check intersection\n",
    "    points_within = df_filtered.geometry.apply(buffer.intersects)\n",
    "    print(points_within.sum())\n",
    "    return df_filtered[points_within].price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uber H3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometry_to_h3(geometry, resolution):\n",
    "    return h3.geo_to_h3(geometry.y, geometry.x, resolution=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h3_to_geometry(h3_index):\n",
    "    return Polygon(h3.h3_to_geo_boundary(h3_index, geo_json=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_h3_df(df, feature, resolution, log=False, year=None):\n",
    "    if year:\n",
    "        df = df[df[\"year\"] == year]\n",
    "    df[\"h3\"] = df.geometry.map(lambda x: geometry_to_h3(x, resolution))\n",
    "    grouped = df.groupby(by=\"h3\")[feature].mean().to_frame().reset_index()\n",
    "    grouped[\"geometry\"] = grouped.h3.map(h3_to_geometry)\n",
    "    if log:\n",
    "        grouped[feature] = np.log(grouped[feature])\n",
    "    return gpd.GeoDataFrame(grouped, crs='EPSG:4326', geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_sales_in_neigh(gdf_sales, gdf, res):\n",
    "    df_grouped = pd.DataFrame()\n",
    "    gdf_tmp = gdf_sales.copy()\n",
    "    gdf_tmp = gdf_tmp.drop_duplicates(subset=\"id\")\n",
    "    for year in gdf_tmp.year.unique():\n",
    "        grouped = get_grouped_h3_df(gdf_tmp, \"price\", res, year=year)\n",
    "        grouped[\"year\"] = year\n",
    "        df_grouped = pd.concat([df_grouped, grouped])\n",
    "\n",
    "    gdf[\"h3\"] = gdf.geometry.map(lambda x: geometry_to_h3(x, res))\n",
    "    gdf[\"prev_year\"] = gdf[\"year\"]-1\n",
    "\n",
    "    gdf_sorted = gdf.reset_index().sort_values(by=['prev_year'])\n",
    "    df_grouped_sorted = df_grouped.sort_values(by=['year'])\n",
    "\n",
    "    # Perform the asof merge\n",
    "    merged_df = pd.merge_asof(\n",
    "        gdf_sorted, \n",
    "        df_grouped_sorted, \n",
    "        left_on='prev_year', \n",
    "        right_on=\"year\",\n",
    "        left_by='h3', \n",
    "        right_by='h3', \n",
    "        direction='backward', \n",
    "        allow_exact_matches=True,  # This ensures we only get previous years, not the same year\n",
    "        suffixes=('', '_right')\n",
    "    )\n",
    "    return merged_df[[\"index\", \"id\", \"longitude\", \"year\", \"month\", \"price\", \"h3\", \"price_right\", \"year_right\"]].rename(columns={\"price_right\": \"neigh_price\"}).set_index(\"index\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_index()\n",
    "df_test = df_test.sort_index()\n",
    "df_val = df_val.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = get_past_sales_in_neigh(gdf_train, gdf_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"price_level\"] = np.nan\n",
    "for i in range(8):\n",
    "    merge_df = get_past_sales_in_neigh(gdf_train, gdf_train, i)\n",
    "    merge_df.loc[((merge_df[\"year\"] - merge_df[\"year_right\"]) > 10), \"neigh_price\"] = np.nan\n",
    "    df_train[\"price_level\"] = np.where(df_train.price_level.isna(), merge_df.neigh_price, df_train.price_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"price_level\"] = np.nan\n",
    "for i in range(8):\n",
    "    merge_df = get_past_sales_in_neigh(gdf_train, gdf_test, i)\n",
    "    merge_df.loc[((merge_df[\"year\"] - merge_df[\"year_right\"]) > 10), \"neigh_price\"] = np.nan\n",
    "    df_test[\"price_level\"] = np.where(df_test.price_level.isna(), merge_df.neigh_price, df_test.price_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"price_level\"] = np.nan\n",
    "for i in range(8):\n",
    "    merge_df = get_past_sales_in_neigh(gdf_train, gdf_val, i)\n",
    "    merge_df.loc[((merge_df[\"year\"] - merge_df[\"year_right\"]) > 10), \"neigh_price\"] = np.nan\n",
    "    df_val[\"price_level\"] = np.where(df_val.price_level.isna(), merge_df.neigh_price, df_val.price_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"data/past_sales/df_train_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"data/past_sales/df_test_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_csv(\"data/past_sales/df_val_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
