{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Modelling (Encodings) \n",
    "\n",
    "In this notebook, we test different city encodings including target encoding, ordinal encoding and language model encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/target_encoding/df_train_encoded_target.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"data/df_test_2.csv\", index_col=0)\n",
    "df_val = pd.read_csv(\"data/df_val_2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"price\", \"id\"])\n",
    "X_val = df_val.drop(columns=[\"price\", \"id\"])\n",
    "X_test = df_test.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "y_train = df_train.loc[:, \"price\"]\n",
    "y_val = df_val.loc[:, \"price\"]\n",
    "y_test = df_test.loc[:, \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some loss functions\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return np.mean(200 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    epsilon = 1e-6  # Small constant to avoid division by zero\n",
    "    return np.sqrt(np.mean(((y_true - y_pred) / (y_true + epsilon)) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use transformer embeddings for city description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuned DistillBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetune_encoding = pd.read_csv(\"data/finetune_encoding.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetune_encoding = df_finetune_encoding.drop(columns=[\"description\", \"county\", \"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"data/df_all.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"city_desc\"] = df_all.loc[df_train.index].city\n",
    "X_val[\"city_desc\"] = df_all.loc[df_val.index].city\n",
    "X_test[\"city_desc\"] = df_all.loc[df_test.index].city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_distill = X_train.merge(df_finetune_encoding, how=\"left\", left_on=\"city_desc\", right_on=\"city\")\n",
    "X_val_distill = X_val.merge(df_finetune_encoding, how=\"left\", left_on=\"city_desc\", right_on=\"city\")\n",
    "X_test_distill = X_test.merge(df_finetune_encoding, how=\"left\", left_on=\"city_desc\", right_on=\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_distill = X_train_distill.drop(columns=[\"city_desc\", \"city_y\"])\n",
    "X_test_distill = X_test_distill.drop(columns=[\"city_desc\", \"city_y\"])\n",
    "X_val_distill = X_val_distill.drop(columns=[\"city_desc\", \"city_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 39660029912.62561\n",
      "MAE: 59758.32820244795\n",
      "MAPE: 27.824942871981506\n",
      "R2: 0.8103508449225142\n",
      "RMSE: 199148.26113382363\n",
      "SMAPE: 15.532924894071122\n",
      "RMSPE: 1880.848403449926\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_distill, y_train)\n",
    "y_hat = model.predict(X_val_distill)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 39626861341.84901\n",
      "MAE: 59825.11948297643\n",
      "MAPE: 26.676661351653383\n",
      "R2: 0.8105094527560627\n",
      "RMSE: 199064.96764084083\n",
      "SMAPE: 15.603688051883815\n",
      "RMSPE: 1665.8716097177432\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_distill.drop(columns=\"city_x\"), y_train)\n",
    "y_hat = model.predict(X_val_distill.drop(columns=\"city_x\"))\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finetuned distillBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distill_pca = pd.DataFrame(pca.fit_transform(df_finetune_encoding.drop(columns=\"city\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distill_pca[\"city\"] = df_finetune_encoding.city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"city_desc\"] = df_all.loc[df_train.index].city\n",
    "X_val[\"city_desc\"] = df_all.loc[df_val.index].city\n",
    "X_test[\"city_desc\"] = df_all.loc[df_test.index].city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_distill_pca = X_train.merge(df_distill_pca, how=\"left\", left_on=\"city_desc\", right_on=\"city\")\n",
    "X_val_distill_pca = X_val.merge(df_distill_pca, how=\"left\", left_on=\"city_desc\", right_on=\"city\")\n",
    "X_test_distill_pca = X_test.merge(df_distill_pca, how=\"left\", left_on=\"city_desc\", right_on=\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_distill_pca = X_train_distill_pca.drop(columns=[\"city_desc\", \"city_y\"])\n",
    "X_test_distill_pca = X_test_distill_pca.drop(columns=[\"city_desc\", \"city_y\"])\n",
    "X_val_distill_pca = X_val_distill_pca.drop(columns=[\"city_desc\", \"city_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 39652496302.67639\n",
      "MAE: 59925.448281221914\n",
      "MAPE: 27.649414421456086\n",
      "R2: 0.8103868696750094\n",
      "RMSE: 199129.34565923826\n",
      "SMAPE: 15.589927156941393\n",
      "RMSPE: 1929.5510105363237\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_distill_pca, y_train)\n",
    "y_hat = model.predict(X_val_distill_pca)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- best performance with parameters (0.7856264868872997):\n",
    "- n_estimators: 350, learning_rate: 0.1, max_depth: 10, pca: 3, random_state=56 and still onehot-encoding of city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 39289647319.524734\n",
      "MAE: 59837.555903141205\n",
      "MAPE: 27.456369447054737\n",
      "R2: 0.8121219667797528\n",
      "RMSE: 198216.1631137197\n",
      "SMAPE: 15.620485226565794\n",
      "RMSPE: 1832.84401677657\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"objective\": 'reg:squarederror',\n",
    "            \"n_estimators\":350,  # Number of boosting rounds\n",
    "            \"learning_rate\":0.1,  # Step size shrinkage\n",
    "            \"max_depth\":10,  # Maximum depth of a tree\n",
    "            }\n",
    "\n",
    "    \n",
    "model = XGBRegressor(**parameters)\n",
    "model.fit(X_train_distill_pca.drop(columns=\"city_x\"), y_train)\n",
    "y_hat = model.predict(X_val_distill_pca.drop(columns=\"city_x\"))\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"R2: {r2_score(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSE: {rmse(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"SMAPE: {smape(y_true=y_val, y_pred=y_hat)}\")\n",
    "print(f\"RMSPE: {rmspe(y_true=y_val, y_pred=y_hat)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
